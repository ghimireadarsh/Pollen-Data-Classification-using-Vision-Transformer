{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this, the MLP head is added and only the head is trained on the data, while the transformer block are kept frozen. \n",
        "\n",
        "Resulting in giving about 89-90% test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTRsPlACdQ_1",
        "outputId": "ef97c9f7-aaca-45e0-966e-c49663e66c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-12-02T18:32:25.025299Z",
          "iopub.status.busy": "2020-12-02T18:32:25.024308Z",
          "iopub.status.idle": "2020-12-02T18:34:10.700354Z",
          "shell.execute_reply": "2020-12-02T18:34:10.699640Z"
        },
        "id": "vsaq89tjIGQ4",
        "outputId": "ecdb12fd-37a7-4df1-a2a0-1e0a98484f8f",
        "papermill": {
          "duration": 105.718607,
          "end_time": "2020-12-02T18:34:10.700500",
          "exception": false,
          "start_time": "2020-12-02T18:32:24.981893",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:10.826084Z",
          "iopub.status.busy": "2020-12-02T18:34:10.824931Z",
          "iopub.status.idle": "2020-12-02T18:34:13.015202Z",
          "shell.execute_reply": "2020-12-02T18:34:13.015867Z"
        },
        "id": "Y5fsmaS4IGQ4",
        "papermill": {
          "duration": 2.258623,
          "end_time": "2020-12-02T18:34:13.016037",
          "exception": false,
          "start_time": "2020-12-02T18:34:10.757414",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import timm\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn import model_selection, metrics\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.273861Z",
          "iopub.status.busy": "2020-12-02T18:34:13.273082Z",
          "iopub.status.idle": "2020-12-02T18:34:13.288963Z",
          "shell.execute_reply": "2020-12-02T18:34:13.288196Z"
        },
        "id": "WTO_w_wEIGQ5",
        "papermill": {
          "duration": 0.083797,
          "end_time": "2020-12-02T18:34:13.289095",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.205298",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproductibility of results\n",
        "    \n",
        "    Arguments:\n",
        "        seed {int} -- Number of the seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed_everything(1001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9b06LUPdD7p",
        "outputId": "1aff99e0-4253-4ae9-a6cb-a9faf61bfe8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pollen_data.zip  test.zip  train.zip\n"
          ]
        }
      ],
      "source": [
        "!ls \"gdrive/MyDrive/Machine Vision and Image Processing/Project/Dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57XALDSLdfIi",
        "outputId": "9a24758a-89ff-42ad-81bd-8ee3e5681c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace Pollen_data/images/20190402172108_OBJ_4_1107_445.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!unzip -q \"gdrive/MyDrive/Machine Vision and Image Processing/Project/Dataset/Pollen_data.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO_RjEdTd95Q"
      },
      "source": [
        "## Loading the prepared Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n4CB2Gp2cPe5"
      },
      "outputs": [],
      "source": [
        "# general global variables\n",
        "DATA_PATH = \"Pollen_data\"\n",
        "IMAGES_PATH = \"Pollen_data/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.557875Z",
          "iopub.status.busy": "2020-12-02T18:34:13.557096Z",
          "iopub.status.idle": "2020-12-02T18:34:13.603956Z",
          "shell.execute_reply": "2020-12-02T18:34:13.603128Z"
        },
        "id": "KZ84J__pIGQ5",
        "outputId": "710b3680-c79a-45f1-88e0-531d05d2ca2d",
        "papermill": {
          "duration": 0.114526,
          "end_time": "2020-12-02T18:34:13.604087",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.489561",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20190404111949_OBJ_0_1080_876.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20190404110111_OBJ_27_393_106.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20190404114349_OBJ_24_349_190.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20190404112959_OBJ_33_841_184.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20190404110146_OBJ_3_444_825.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_id  label\n",
              "0  20190404111949_OBJ_0_1080_876.png      0\n",
              "1  20190404110111_OBJ_27_393_106.png      0\n",
              "2  20190404114349_OBJ_24_349_190.png      0\n",
              "3  20190404112959_OBJ_33_841_184.png      0\n",
              "4   20190404110146_OBJ_3_444_825.png      0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(os.path.join(DATA_PATH, \"data.csv\"))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.744267Z",
          "iopub.status.busy": "2020-12-02T18:34:13.736833Z",
          "iopub.status.idle": "2020-12-02T18:34:13.752203Z",
          "shell.execute_reply": "2020-12-02T18:34:13.752809Z"
        },
        "id": "DOvQ3r_KIGQ6",
        "outputId": "1910ae25-499d-44ac-d578-781a1c5d5ca6",
        "papermill": {
          "duration": 0.087447,
          "end_time": "2020-12-02T18:34:13.752968",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.665521",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11279 entries, 0 to 11278\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   image_id  11279 non-null  object\n",
            " 1   label     11279 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 176.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.889294Z",
          "iopub.status.busy": "2020-12-02T18:34:13.888176Z",
          "iopub.status.idle": "2020-12-02T18:34:14.103989Z",
          "shell.execute_reply": "2020-12-02T18:34:14.103314Z"
        },
        "id": "-DUxwZqnIGQ6",
        "outputId": "7ead5ff5-acb9-46c3-937c-e745afeb4624",
        "papermill": {
          "duration": 0.288382,
          "end_time": "2020-12-02T18:34:14.104118",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.815736",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2da3711ad0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.label.value_counts().plot(kind=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IamQAhx8KBge"
      },
      "outputs": [],
      "source": [
        "# Here for splitting the data into train, test and validation. We will using train_test_split from sklearn\n",
        "\n",
        "# First divide the data into train data (80%) and remaining data(20%)\n",
        "# Secodn divide the remaining data into validation (10%) and test data(10%)\n",
        "train_df, remaining_df = model_selection.train_test_split(df, test_size=0.2, random_state=42, stratify=df.label.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "9N_RAonhLBrr",
        "outputId": "266312c9-fa95-431e-ffe9-a8c2dfd80837"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training data distribution')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training data distribution\n",
        "train_df.label.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Training data distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiQiOcbELnfu",
        "outputId": "d4ed813c-b354-4ce1-95d1-d6cb83acc11e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    6573\n",
              "0    1253\n",
              "1     618\n",
              "3     579\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.240631Z",
          "iopub.status.busy": "2020-12-02T18:34:14.239815Z",
          "iopub.status.idle": "2020-12-02T18:34:14.272019Z",
          "shell.execute_reply": "2020-12-02T18:34:14.271271Z"
        },
        "id": "cQKqI5lxIGQ6",
        "outputId": "d9bc5462-77aa-4f6f-a0cb-b640ad118202",
        "papermill": {
          "duration": 0.102979,
          "end_time": "2020-12-02T18:34:14.272159",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.169180",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Except training data distribution')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfVRU9aI//vdmBtBheJpBIBQfEK3wCQsVNQV1bqeO5fXYOa5O2tG0yGj5WC3R0tPNMFpdhPAhz5Uudq1zKyvRW3mriYBTHG+jMD5hIKYWRxSZQQ6IycN8fn/4c38beVLYAw77/VqLtdyfvfdnfz4fxvfe85nNbEkIIUBERKrg0dMNICKi7sPQJyJSEYY+EZGKMPSJiFSEoU9EpCIMfSIiFWHo023lzJkzkCQJ33777S3tN3jwYLz66qsualXH4uPj8eSTT/bY8Vtz45i4cowWLlwIk8nU5rLSbsfxdhcM/W60cOFCSJLU4kev1/d001owmUxYuHBhh9u9+uqrGDx4sGLHDQ8PR0VFBSZMmHBL+1ksFqxcuVKxdrhaeXk5JElCbm5utx3zVsbo22+/hSRJOHPmzE1t/+abb2L37t1daF3r2np9ffLJJ9i0aZPix1MDbU83QG2mTJmCDz/80KnMw6P3n3sbGhrg5eXV4XYajQahoaG3XH+/fv060yxVccUYNTY2wtPTE/7+/orX3R6DwdCtx+tNen/a3Ga8vLwQGhrq9BMcHAwAsNvtCA8Px/Lly+XtKysrcccdd2Dt2rVymdlsxpQpU6DT6eDv74+4uDicOnVKXv/+++8jOjoaffr0weDBg7Fq1SpcvnxZXh8fH49FixYhKSkJQUFB8PPzQ0JCAn755RcA196RfP3113jnnXfkdyOtXZHu3LkT69atw9mzZ+XtXn75ZQDXphJeeuklJCYmwmg0YsqUKQCuXRFGR0dDr9cjNDQUjz76KCoqKuQ6b5zeub784Ycf4qGHHoJOp0NERAR27tzp1JbWpjLWr1+P5cuXw2AwICQkBCtXrkRTU5O8zZUrV5CQkAB/f38EBgYiMTERa9asQWRkZLu/w7Nnz+KBBx5A3759ER4ejs2bN7fY5q9//SsmTJgAf39/BAUFYebMmSgtLZXXh4eHAwCmTZsGSZLkq9nTp09jzpw5CAsLg06nw6hRo7Br16522wMAhw8fxqRJk+Dt7Y1hw4a1uLBobYz27t2LsWPHQqfTISAgAOPHj0dRURHOnDkj/76GDBkCSZIQHx8P4P9N22zevBmDBw+Gt7c3rly50uZ0TlpaGvr37w+dToc//OEPsNvt8rrW9nn33XchSRKA9l9fN07vNDY2IikpCf3794eXlxeioqLw17/+1aluSZKwbds2PP744/D19cWAAQPw2muvdTi2vY6gbrNgwQIxY8aMdrfJy8sTWq1W7Nu3TzgcDnH//feLiRMnisbGRiGEEF999ZXw8PAQy5cvF1arVZw4cUJkZmaKEydOCCGEyMrKEgEBAeK//uu/xKlTp0ReXp4YNWqUmD9/vnyMuLg44evrK5588klRXFws9u3bJ/r16ydWrFghhBDi0qVLYsqUKWLu3LmioqJCVFRUiKtXr7Zoa319vVi9erUYMGCAvF1tba0QQohBgwYJX19f8ec//1mUlJSI48ePCyGESE9PF1999ZX48ccfRUFBgZg4caKYOnWqXOfp06cFAPG3v/3NaXnIkCHigw8+ECdPnhRr1qwRGo1GlJSUyPsNGjRIbNiwwWk5ICBAvPbaa6K0tFR88MEHQqvViszMTHmbpUuXiuDgYLF3717xww8/iKSkJOHn5yeGDh3a5u/H4XCIsWPHipiYGHHgwAFRVFQkTCaT8PX1FYsXL5a3+8///E+xb98+UVZWJgoLC8XDDz8sIiMj5XEsLCwUAMTHH38sKioqRGVlpRBCiCNHjojNmzcLq9UqysrKREZGhtBoNCInJ6fNNtXX14uwsDDx4IMPCqvVKgoKCkRMTIzo27dvizG5vlxRUSE8PT3F66+/Ln788UdRXFws3nvvPXHkyBHR1NQk9u7dKwCI77//XlRUVAibzSaEuPYa9vX1FbNnzxZWq1Xe/sbX9vXtHn74YXHkyBHxzTffiMjISDF79mynbW78/7Br1y5xPZbae33FxcU5jffzzz8vDAaD+PDDD0VJSYlITk4WkiQJs9ksbwNABAcHi//4j/8QZWVlYsuWLQKA0zZqwNDvRgsWLBAajUb4+Pg4/Tz00ENO27388svCaDSKVatWiYCAAHHmzBl53X333SdmzpzZ5jEGDRok3nrrLaeyvLw8AUDY7XYhxLX/MIMGDRJNTU3yNn/5y1+Et7e3qKurE0IIMWPGDLFgwYIO+7RhwwYxaNCgVtsxffr0Dve/Hn7l5eVCiLZDPzU1Vd6nqalJ6PV6sX37dqfj3RhwDz/8sNOxHnjgAfHoo48KIYSoq6sTXl5eTicBIYSYMGFCu6H/1VdfCQBOJ5zKykrRp08fpxC6kc1mEwDEt99+K4QQ4ueffxYAxDfffNPmPtfNmjVLPPnkk22u37Fjh/Dx8ZF/v0IIcfToUQGgzdC/Pu6nT59utc6//e1vra5fsGCB8Pf3l8P31+U3hr6Pj4+4dOmSXPbFF18IAOLkyZOt7iOEc+gL0fbr69ehf/nyZeHl5SW2bt3qtM3s2bPFtGnT5GUAYunSpU7b3HXXXSIpKanVMeitOL3TzSZMmACr1er085e//MVpm3Xr1mH48OHYtGkTtm/fjkGDBsnrDh06hPvvv7/Vui9evIizZ89i1apV0Ov18s+DDz4IACgrK5O3HT9+PDQajbw8efJkXL161WmaqKvGjx/foiw3Nxe/+c1vEB4eDl9fX9x3330Ark2ZtCc6Olr+t0ajQXBwMC5cuHDT+wBAWFiYvE9ZWRkaGhoQGxvrtM3EiRPbrbO4uBhBQUEYPny4XNavXz/ceeedTttZrVb87ne/w5AhQ+Dr64uBAwcC6Lif9fX1SEpKwogRI2AwGKDX6/H555+3u19xcTHuvvtuBAYGymUjR45sd5599OjR+M1vfoORI0fid7/7Hd588038/PPP7bbturvvvvumbj6IiopyasPkyZPl9irp+u9y6tSpTuVxcXE4fvy4U1l7rwm14Ae53axv374dzhlXVFSgtLQUGo3GaR64Iw6HA8C1efNp06a1WD9gwIBba2wX+fj4OC3/9NNP+O1vf4vHH38c69evR1BQEMrLy2EymdDQ0NBuXTd+CCxJktzfruxzff5YSfX19bj//vtx3333ISsrCyEhIQCAESNGdNjPF154AXv37sWmTZtw5513wsfHB8899xxqamoUbaNGo8H+/fthsVhgNpvx8ccfIykpCbt378ZDDz3U7r43/l47y8PDA+KGL/ltbGxUpO62dOZ11NvwSv8243A4MG/ePIwZMwYffPABXnnlFRQUFMjr7733Xnz55Zet7hsSEoLw8HCUlJQgMjKyxU+fPn3kbS0WC5qbm+XlgoICeHt7Y+jQoQCu/ef49fq23Ox214955coVpKenY/Lkybjzzjt77CorMjISXl5e+Pvf/+5UfuDAgXb3i4qKQlVVFU6ePCmXVVVVoaSkRF4+ceIELl68iOTkZMTHx+Puu+9GdXW1U8BdD58bxy4/Px/z5s3D3LlzMWbMGERERHR44o+KisKJEydw6dIluez48eMdnigkScL48eOxdu1a5OfnIy4uDllZWe2271acOHEC//znP+Xl66/jqKgoAEBwcDDOnTvntE9hYaHT8s28viIjI+Ht7Y38/Hyn8ry8PIwcObLT7e+tGPrdrKGhAefPn2/xcz0QkpOTcfz4cezatQuPPPIIEhIS8Nhjj8n/odetW4f9+/djxYoVOHLkCEpKSrBz5045dJKTk5GRkYHk5GQcO3YMJSUlyM7OxtNPP+3UDpvNhmeffRYnTpzAZ599hnXr1uHpp5+Wr+KGDBmCQ4cO4dSpU6iqqmrzCmzIkCE4f/48/v73v6Oqqgr19fVt9n3YsGGQJAmpqak4ffo0srOz8corr3R5TDvDx8cHTz/9NF566SV8+umnKC0txYsvvogTJ060e/U/Y8YMjBkzBvPnz8f3338Pq9WKefPmwdPTU95m0KBB8Pb2xubNm3Hq1Cl8/fXXWL58uVO9QUFB0Ov1+PLLL3H+/HlUV1cDAO68807s3bsX33//PYqLi5GQkNAiGG/02GOPwdfXF/Pnz8fhw4dx4MABLFq0CH379m1zn4KCAmzYsAH/93//h59++glff/01jhw5IgfyoEGD4OHhgc8//xyVlZWdeqchSRL+9Kc/4dixY8jPz8ezzz6LWbNmye90TSYTfvjhB2zduhWnTp3Cjh07Wtx1dDOvL51Oh2XLlmHdunXYvXs3SktLsXHjRuzdu9fprjf6//XwZwqqsmDBAgGg1Z+LFy+K7777Tr5z57orV66I0aNHiz/84Q9y2f/+7/+K2NhY0adPH+Hn5yfi4+PFqVOn5PV79uwRsbGxom/fvsLX11eMGTNG/Nu//Zu8Pi4uTjzxxBPyHQ96vV4sXrxY1NfXy9ucOnVKTJkyRfj4+LT7gWNDQ4P44x//KAIDAwUA8ec//1kI0fKD1eu2bNkiBgwYIPr06SMmT54s9u/f71R/Wx/kXl++bujQofKxWjtea8dfvHixiIuLk5fr6+vFU089JXx9fYW/v7945plnxPLly8XIkSNb7et1p0+fFv/yL/8ivL29Rf/+/UV6enqLu0l2794tIiMjhbe3t4iOjha5ublCo9GIrKwseZt33nlHDB48WGg0GvnDyp9++kncf//9QqfTidDQULF+/XqxaNEip3a3prCwUMTGxgovLy8REREh/vu//7vdMTl27Jh48MEHRUhIiPDy8hIDBw4Uzz//vNNdWq+//roICwsTHh4e8vHbugOttQ9yZ8yYId544w0RGhoq+vbtK+bMmSOqqqqc9nv11VdFWFiY8PHxEY8++qh8R811bb2+bhzvhoYGsXr1ahEWFiY8PT3F3XffLd577z2nYwEQu3btciq72RsWehNJCD45S23i4+MRGRmJzMzMnm7KbWf69OkIDAzExx9/3NNNIXIJfpBLqnX06FEUFhZi4sSJaGhowK5du/DNN99g//79Pd00Ipdh6JNqSZKEt956C8uWLYPD4cBdd92FPXv24IEHHujpphG5DKd3iIhUhHfvEBGpCEOfiEhFGPpERCpy23+Q29EfptwOgoKCUFVV1dPN6DU4nsrieCrHXcYyLCyszXW80iciUhGGPhGRijD0iYhUhKFPRKQiDH0iIhVh6BMRqQhDn4hIRRj6REQqctv/cZbSmp+apXidrnjgn2bHPhfUSkRqxyt9IiIV6fBKf9u2bSgsLIS/vz9SU1Pl8v379+OLL76Ah4cH7rnnHsyfPx8AsGfPHuTk5MDDwwNPPPEEoqOjAQBWqxVZWVlwOByYMWMGZs+e7aIuERFRWzoM/fj4eDzwwAPYunWrXHbs2DEcPHgQb7zxBjw9PeWHJpeXl6OgoACbNm1CdXU1NmzYgDfffBMA8Pbbb+Oll16C0WjEmjVrEBMTgwEDBrioW0RE1JoOQz8qKgqVlZVOZV9++SX+9V//FZ6engAAf39/AIDFYsGkSZPg6emJ4OBghIaGoqysDAAQGhqKkJAQAMCkSZNgsVgY+kRE3axTH+RWVFTghx9+wPvvvw9PT088/vjjiIyMhN1ux7Bhw+TtDAYD7HY7AMBoNMrlRqMRJ0+e7GLTiYjoVnUq9B0OB+rq6pCcnIxTp04hLS0NW7ZsUaRBZrMZZrMZAJCSkoKgoCBF6r3OFXfauILS/XYnWq1W1f1XGsdTOb1hLDsV+gaDAePHj4ckSYiMjISHhwdqa2thMBhgs9nk7ex2OwwGAwA4ldtsNrn8RiaTCSaTSV52h++udgW19htwn+8sdxccT+W4y1gq/n3648aNw/HjxwFce8hJU1MTfH19ERMTg4KCAjQ2NqKyshIVFRWIjIzE0KFDUVFRgcrKSjQ1NaGgoAAxMTGd6w0REXVah1f66enpKC4uRm1tLZYsWYK5c+di+vTp2LZtG5577jlotVo8++yzkCQJ4eHhmDhxIlatWgUPDw8sXrwYHh7XziuLFi1CcnIyHA4Hpk2bhvDwcJd3joiInElCCNHTjWiP0o9LdMVf5LqCmv8i113eQrsLjqdy3GUs+bhEIiICwNAnIlIVhj4RkYow9ImIVIShT0SkIgx9IiIVYegTEakIQ5+ISEUY+kREKsLQJyJSEYY+EZGKMPSJiFSEoU9EpCIMfSIiFWHoExGpCEOfiEhFOnxy1rZt21BYWAh/f3+kpqY6rfuf//kf7Nq1C5mZmfDz84MQAllZWSgqKoK3tzcSExMREREBAMjNzcUnn3wCAJgzZw7i4+OV7w0REbWrwyv9+Ph4rF27tkV5VVUVjhw54vRk+KKiIpw/fx4ZGRlISEhAZmYmAKCurg4fffQRNm7ciI0bN+Kjjz5CXV2dgt0gIqKb0WHoR0VFQa/Xtyh/5513MG/ePEiSJJcdPHgQU6dOhSRJGD58OC5fvozq6mpYrVaMHj0aer0eer0eo0ePhtVqVbYnRETUoU7N6VssFhgMBgwePNip3G63O135G41G2O122O12GI1GudxgMMBut3euxURE1Gkdzunf6OrVq9izZw9eeuklV7QHZrMZZrMZAJCSkuJ0ElHCBUVrcx2l++1OtFqtqvuvNI6ncnrDWN5y6F+4cAGVlZV44YUXAAA2mw2rV6/Ga6+9BoPB4PSkeJvNBoPBAIPBgOLiYrncbrcjKiqq1fpNJhNMJpO87A5PnncFtfYbuHbCU3P/lcbxVI67jGVYWFib6255emfgwIHIzMzE1q1bsXXrVhiNRrz++usICAhATEwM8vPzIYRAaWkpdDodAgMDER0djcOHD6Ourg51dXU4fPgwoqOju9QpIiK6dR1e6aenp6O4uBi1tbVYsmQJ5s6di+nTp7e67dixY1FYWIhly5bBy8sLiYmJAAC9Xo9HHnkEa9asAQD8/ve/b/XDYSIici1JCCF6uhHtOXfunKL1NT81S9H6XEWzY19PN6HHuMtbaHfB8VSOu4ylotM7RETkvhj6REQqwtAnIlIRhj4RkYow9ImIVIShT0SkIgx9IiIVYegTEakIQ5+ISEUY+kREKsLQJyJSEYY+EZGKMPSJiFSEoU9EpCIMfSIiFWHoExGpSIdPztq2bRsKCwvh7++P1NRUAMCuXbtw6NAhaLVahISEIDExET4+PgCAPXv2ICcnBx4eHnjiiSfkxyJarVZkZWXB4XBgxowZmD17tgu7RURErenwSj8+Ph5r1651Khs9ejRSU1Px7//+77jjjjuwZ88eAEB5eTkKCgqwadMmvPjii3j77bfhcDjgcDjw9ttvY+3atUhLS8N3332H8vJy1/SIiIja1GHoR0VFtXie7ZgxY6DRaAAAw4cPh91uBwBYLBZMmjQJnp6eCA4ORmhoKMrKylBWVobQ0FCEhIRAq9Vi0qRJsFgsLugOERG1p8tz+jk5OfIUjt1uh9FolNcZDAbY7fYW5UajUT5REBFR9+lwTr89n3zyCTQaDaZMmaJUe2A2m2E2mwEAKSkpCAoKUqxuALigaG2uo3S/3YlWq1V1/5XG8VRObxjLTod+bm4uDh06hPXr10OSJADXruxtNpu8jd1uh8FgAACncpvNJpffyGQywWQyycvu8OR5V1Brv4FrJzw1919pHE/luMtYhoWFtbmuU9M7VqsVe/fuxerVq+Ht7S2Xx8TEoKCgAI2NjaisrERFRQUiIyMxdOhQVFRUoLKyEk1NTSgoKEBMTExnDk1ERF3Q4ZV+eno6iouLUVtbiyVLlmDu3LnYs2cPmpqasGHDBgDAsGHDkJCQgPDwcEycOBGrVq2Ch4cHFi9eDA+Pa+eVRYsWITk5GQ6HA9OmTUN4eLhre0ZERC1IQgjR041oz7lz5xStr/mpWYrW5yqaHft6ugk9xl3eQrsLjqdy3GUsFZ/eISIi98TQJyJSEYY+EZGKMPSJiFSEoU9EpCIMfSIiFWHoExGpCEOfiEhFGPpERCrC0CciUhGGPhGRijD0iYhUhKFPRKQiDH0iIhVh6BMRqQhDn4hIRRj6REQq0uHjErdt24bCwkL4+/sjNTUVAFBXV4e0tDRcvHgR/fr1w8qVK6HX6yGEQFZWFoqKiuDt7Y3ExEREREQAuPYg9U8++QQAMGfOHMTHx7uuV0RE1KoOr/Tj4+Oxdu1ap7Ls7GyMGjUKGRkZGDVqFLKzswEARUVFOH/+PDIyMpCQkIDMzEwA104SH330ETZu3IiNGzfio48+Ql1dnQu6Q0RE7ekw9KOioqDX653KLBYL4uLiAABxcXGwWCwAgIMHD2Lq1KmQJAnDhw/H5cuXUV1dDavVitGjR0Ov10Ov12P06NGwWq0u6A4REbWnw+md1tTU1CAwMBAAEBAQgJqaGgCA3W5HUFCQvJ3RaITdbofdbofRaJTLDQYD7HZ7q3WbzWaYzWYAQEpKilN9SrigaG2uo3S/3YlWq1V1/5XG8VRObxjLToX+r0mSBEmSlGgLAMBkMsFkMsnL7vDkeVdQa7+Bayc8NfdfaRxP5bjLWIaFhbW5rlN37/j7+6O6uhoAUF1dDT8/PwDXruB/PSA2mw0GgwEGgwE2m00ut9vtMBgMnTk0ERF1QadCPyYmBnl5eQCAvLw8jBs3Ti7Pz8+HEAKlpaXQ6XQIDAxEdHQ0Dh8+jLq6OtTV1eHw4cOIjo5WrhdERHRTOpzeSU9PR3FxMWpra7FkyRLMnTsXs2fPRlpaGnJycuRbNgFg7NixKCwsxLJly+Dl5YXExEQAgF6vxyOPPII1a9YAAH7/+9+3+HCYiIhcTxJCiJ5uRHvOnTunaH3NT81StD5X0ezY19NN6DHuMm/qLjieynGXsVR8Tp+IiNwTQ5+ISEUY+kREKsLQJyJSEYY+EZGKMPSJiFSEoU9EpCIMfSIiFWHoExGpCEOfiEhFGPpERCrC0CciUhGGPhGRijD0iYhUhKFPRKQiDH0iIhXp0oPRP/30U+Tk5ECSJISHhyMxMRGXLl1Ceno6amtrERERgaVLl0Kr1aKxsRFbtmzBjz/+CF9fX6xYsQLBwcFK9YOIiG5Cp6/07XY79u/fj5SUFKSmpsLhcKCgoADvvvsuZs6cic2bN8PHxwc5OTkAgJycHPj4+GDz5s2YOXMm3nvvPcU6QUREN6dL0zsOhwMNDQ1obm5GQ0MDAgICcPz4ccTGxgIA4uPjYbFYAAAHDx5EfHw8ACA2NhbHjh3Dbf6kRiKiXqfT0zsGgwEPP/wwnnnmGXh5eWHMmDGIiIiATqeDRqORt7Hb7QCuvTMwGo0AAI1GA51Oh9raWvj5+SnQDSIiuhmdDv26ujpYLBZs3boVOp0OmzZtgtVq7XKDzGYzzGYzACAlJQVBQUFdrvPXLiham+so3W93otVqVd1/pXE8ldMbxrLToX/06FEEBwfLV+oTJkxASUkJ6uvr0dzcDI1GA7vdDoPBAODaVb/NZoPRaERzczPq6+vh6+vbol6TyQSTySQvu8OT511Brf0Grp3w1Nx/pXE8leMuYxkWFtbmuk7P6QcFBeHkyZO4evUqhBA4evQoBgwYgBEjRuDAgQMAgNzcXMTExAAA7r33XuTm5gIADhw4gBEjRkCSpM4enoiIOqHTV/rDhg1DbGwsVq9eDY1Gg8GDB8NkMuGee+5Beno63n//fQwZMgTTp08HAEyfPh1btmzB0qVLodfrsWLFCsU6QUREN0cSt/ktNOfOnVO0vuanZilan6toduzr6Sb0GHd5C+0uOJ7KcZexdMn0DhERuR+GPhGRijD0iYhUhKFPRKQiDH0iIhVh6BMRqQhDn4hIRRj6REQqwtAnIlIRhj4RkYow9ImIVIShT0SkIgx9IiIVYegTEakIQ5+ISEUY+kREKtLpJ2cBwOXLl7F9+3b8/PPPkCQJzzzzDMLCwpCWloaLFy+iX79+WLlyJfR6PYQQyMrKQlFREby9vZGYmIiIiAil+kFERDehS1f6WVlZiI6ORnp6Ot544w30798f2dnZGDVqFDIyMjBq1ChkZ2cDAIqKinD+/HlkZGQgISEBmZmZinSAiIhuXqdDv76+HidOnJCfgavVauHj4wOLxYK4uDgAQFxcHCwWCwDg4MGDmDp1KiRJwvDhw3H58mVUV1cr0AUiIrpZnZ7eqayshJ+fH7Zt24azZ88iIiICCxcuRE1NDQIDAwEAAQEBqKmpAQDY7XYEBQXJ+xuNRtjtdnlbIiJyvU6HfnNzM06fPo1FixZh2LBhyMrKkqdyrpMkCZIk3VK9ZrMZZrMZAJCSkuJ0olDCBUVrcx2l++1OtFqtqvuvNI6ncnrDWHY69I1GI4xGI4YNGwYAiI2NRXZ2Nvz9/VFdXY3AwEBUV1fDz88PAGAwGJyeIm+z2WAwGFrUazKZYDKZ5GV3ePK8K6i138C1E56a+680jqdy3GUsw8LC2lzX6Tn9gIAAGI1GnDt3DgBw9OhRDBgwADExMcjLywMA5OXlYdy4cQCAmJgY5OfnQwiB0tJS6HQ6Tu0QEXWzLt2yuWjRImRkZKCpqQnBwcFITEyEEAJpaWnIycmRb9kEgLFjx6KwsBDLli2Dl5cXEhMTFekAERHdPEkIIXq6Ee25/k5CKc1PzVK0PlfR7NjX003oMe7yFtpdcDyV4y5j6ZLpHSIicj8MfSIiFWHoExGpCEOfiEhFGPpERCrC0CciUhGGPhGRijD0iYhUhKFPRKQiDH0iIhVh6BMRqQhDn4hIRRj6REQqwtAnIlIRhj4RkYow9ImIVKRLT84CAIfDgaSkJBgMBiQlJaGyshLp6emora1FREQEli5dCq1Wi8bGRmzZsgU//vgjfH19sWLFCgQHByvRByIiukldvtL//PPP0b9/f3n53XffxcyZM7F582b4+PggJycHAJCTkwMfHx9s3rwZM2fOxHvvvdfVQxMR0S3qUujbbDYUFhZixowZAAAhBI4fP47Y2FgAQHx8PCwWCwDg4MGDiI+PBwDExsbi2LFjuHCB23gAAAgJSURBVM2f1EhE1Ot0KfR37tyJ+fPnQ5IkAEBtbS10Oh00Gg0AwGAwwG63AwDsdjuMRiMAQKPRQKfToba2tiuHJyKiW9TpOf1Dhw7B398fEREROH78uGINMpvNMJvNAICUlBQEBQUpVjcAXFC0NtdRut/uRKvVqrr/SuN4Kqc3jGWnQ7+kpAQHDx5EUVERGhoacOXKFezcuRP19fVobm6GRqOB3W6HwWAAcO2q32azwWg0orm5GfX19fD19W1Rr8lkgslkkpfd4cnzrqDWfgPXTnhq7r/SOJ7KcZexDAsLa3Ndp6d3HnvsMWzfvh1bt27FihUrMHLkSCxbtgwjRozAgQMHAAC5ubmIiYkBANx7773Izc0FABw4cAAjRoyQp4WIiKh7KH6f/rx58/Dpp59i6dKlqKurw/Tp0wEA06dPR11dHZYuXYpPP/0U8+bNU/rQRETUAUnc5rfQnDt3TtH6mp+apWh9rqLZsa+nm9Bj3OUttLvgeCrHXcbSJdM7RETkfhj6REQqwtAnIlIRhj4RkYow9ImIVIShT0SkIl3+amVSN1fcAuuKr8pQ8y2wRL/GK30iIhVh6BMRqQhDn4hIRRj6REQqwtAnIlIRhj4RkYow9ImIVIShT0SkIgx9IiIV6fRf5FZVVWHr1q24dOkSJEmCyWTCb3/7W9TV1SEtLQ0XL15Ev379sHLlSuj1egghkJWVhaKiInh7eyMxMRERERFK9oWIiDrQ6St9jUaDxx9/HGlpaUhOTsYXX3yB8vJyZGdnY9SoUcjIyMCoUaOQnZ0NACgqKsL58+eRkZGBhIQEZGZmKtYJIiK6OZ0O/cDAQPlKvW/fvujfvz/sdjssFgvi4uIAAHFxcbBYLACAgwcPYurUqZAkCcOHD8fly5dRXV2tQBeIiOhmKTKnX1lZidOnTyMyMhI1NTUIDAwEAAQEBKCmpgYAYLfbERQUJO9jNBpht9uVODwREd2kLn/L5i+//ILU1FQsXLgQOp3OaZ0kSZAk6ZbqM5vNMJvNAICUlBSnE4USXPENjq6gdL9dheN5+9Nqtaruv5J6w1h2KfSbmpqQmpqKKVOmYMKECQAAf39/VFdXIzAwENXV1fDz8wMAGAwGp6fI22w2GAyGFnWaTCaYTCZ52R2ePO8Kau23q6h5PIOCglTdfyW5y1iGhYW1ua7T0ztCCGzfvh39+/fHQw89JJfHxMQgLy8PAJCXl4dx48bJ5fn5+RBCoLS0FDqdTp4GIiKi7tHpK/2SkhLk5+dj4MCBeOGFFwAAf/zjHzF79mykpaUhJydHvmUTAMaOHYvCwkIsW7YMXl5eSExMVKYHRER00zod+nfddRc+/PDDVtetX7++RZkkSXjyySc7ezgiIlIA/yKXiEhF+IxcotsInzlMrsbQJ6JeiSfQ1nF6h4hIRRj6REQqwtAnIlIRhj4RkYow9ImIVIShT0SkIgx9IiIVYegTEakIQ5+ISEUY+kREKsLQJyJSEYY+EZGKMPSJiFSEoU9EpCLd/tXKVqsVWVlZcDgcmDFjBmbPnt3dTSAiUq1uvdJ3OBx4++23sXbtWqSlpeG7775DeXl5dzaBiEjVujX0y8rKEBoaipCQEGi1WkyaNAkWi6U7m0BEpGrdOr1jt9thNBrlZaPRiJMnTzptYzabYTabAQApKSkICwtTthGfHVS2PrXjeCqL46kcjmWrbrsPck0mE1JSUpCSktLTTblpSUlJPd2EXoXjqSyOp3J6w1h2a+gbDAbYbDZ52WazwWAwdGcTiIhUrVtDf+jQoaioqEBlZSWamppQUFCAmJiY7mwCEZGqdeucvkajwaJFi5CcnAyHw4Fp06YhPDy8O5vgEiaTqaeb0KtwPJXF8VRObxhLSQgheroRRETUPW67D3KJiMh1GPpERCrC0CciUpFu/+6d3uAf//gH7HY7hg0bhj59+sjlVqsV0dHRPdgy9/SPf/wDFosFdrsdwLVbe2NiYjBgwIAebhmpXVlZGQAgMjIS5eXlsFqtCAsLwz333NPDLes8fpB7iz7//HN88cUX6N+/P86ePYuFCxdi3LhxAIDVq1fj9ddf7+EWupfs7Gx89913mDx5svw3G3a7XS7jF/Ip55tvvsG0adN6uhluY/fu3bBarWhubsbo0aNx8uRJjBgxAkePHsWYMWMwZ86cnm5i5wi6JatWrRJXrlwRQghx4cIFsXr1avHZZ58JIYR44YUXerJpbmnZsmWisbGxRXljY6NYunRpD7So91qyZElPN8GtrFq1SjQ3N4tffvlF/OlPfxKXL18WQghx9epV8dxzz/Vw6zqP0zu3SAghT+kEBwfj5ZdfRmpqKi5evAjBN023TJIkVFdXo1+/fk7l1dXVkCSph1rlvp5//vlWy4UQqKmp6ebWuDeNRgMPDw94e3sjJCQEOp0OAODl5eXWr02G/i3y9/fHmTNnMHjwYABAnz59kJSUhLfeegs//fRTzzbODS1cuBCvvPIK7rjjDvnL+KqqqnD+/HksXry4h1vnfmpqavDiiy/Cx8fHqVwIgXXr1vVQq9yTVqvF1atX4e3t7fRdYPX19fDwcN97YDinf4tsNhs0Gg0CAgJarPvhhx9w11139UCr3JvD4UBZWZnTB7mRkZFu/R+rp7z11luYNm1aq6/DN998E8uXL++BVrmnxsZGeHp6tij/5z//iUuXLmHgwIE90KquY+gTEakIL6WIiFSEoU9EpCIMfSIiFWHoExGpCEOfiEhF/j/IBo5QM/7+iwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "remaining_df.label.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Except training data distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TfyP5ENmLNAK"
      },
      "outputs": [],
      "source": [
        "valid_df, test_df = model_selection.train_test_split(remaining_df, test_size=0.5, random_state=42, stratify=remaining_df.label.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2d8YNZyL5QL",
        "outputId": "277b192a-0858-40a8-ff87-d32ed70ef085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    821\n",
              "0    156\n",
              "1     78\n",
              "3     73\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Ez-Q5OmmLV3G",
        "outputId": "5bef3e74-a94c-477f-8a7c-4be68d3c58f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation data distribution')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "valid_df.label.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Validation data distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEcVADBXMCAi",
        "outputId": "d82ba0f8-89bb-44a8-aeba-9880e142dd5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "jx_vit_base_p16_224-80ecf9dd.pth.zip\n"
          ]
        }
      ],
      "source": [
        "!ls \"gdrive/MyDrive/Machine Vision and Image Processing/Project/pretrained_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9u6VH4sqL9o4"
      },
      "outputs": [],
      "source": [
        "# Getting the pretrained transformer model into the current running environment\n",
        "!unzip -q \"gdrive/MyDrive/Machine Vision and Image Processing/Project/pretrained_model/jx_vit_base_p16_224-80ecf9dd.pth.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OP2_rWBnb_AJ"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = (\"jx_vit_base_p16_224-80ecf9dd.pth\")\n",
        "\n",
        "\n",
        "# model specific global variables\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3j1GPamiMgrA",
        "outputId": "fd269cbc-68ed-4d4d-9c46-1ed0adbac592"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Pollen_data'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmzFbWa9MsLN",
        "outputId": "da485ea1-17af-4d49-98bb-56d2fa7a603c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11279"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.419320Z",
          "iopub.status.busy": "2020-12-02T18:34:14.418142Z",
          "iopub.status.idle": "2020-12-02T18:34:14.444009Z",
          "shell.execute_reply": "2020-12-02T18:34:14.443354Z"
        },
        "id": "X10x9aa4IGQ6",
        "papermill": {
          "duration": 0.106308,
          "end_time": "2020-12-02T18:34:14.444148",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.337840",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "class PollenDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Helper Class to create the pytorch dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, data_path=DATA_PATH, transforms=None):\n",
        "        super().__init__()\n",
        "        self.df_data = df.values\n",
        "        self.data_path = data_path\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = \"images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name, label = self.df_data[index]\n",
        "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        label = np.asarray(label, dtype='int64')\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(img)\n",
        "\n",
        "        return image, torch.from_numpy(label)\n",
        "        # return img_name, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.590922Z",
          "iopub.status.busy": "2020-12-02T18:34:14.589829Z",
          "iopub.status.idle": "2020-12-02T18:34:14.612461Z",
          "shell.execute_reply": "2020-12-02T18:34:14.611720Z"
        },
        "id": "vj0xgpWNIGQ7",
        "papermill": {
          "duration": 0.101631,
          "end_time": "2020-12-02T18:34:14.612584",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.510953",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# create image augmentations\n",
        "\n",
        "transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transforms_valid = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "p9rKlbPSz3wE"
      },
      "outputs": [],
      "source": [
        "# Train and validation dataset with transformations\n",
        "train_dataset = PollenDataset(train_df, transforms=transforms_train)\n",
        "valid_dataset = PollenDataset(valid_df, transforms=transforms_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qLsdoP4iz7mJ"
      },
      "outputs": [],
      "source": [
        "# Train and validation loader \n",
        "train_loader = DataLoader(\n",
        "     dataset=train_dataset,\n",
        "     batch_size=BATCH_SIZE,\n",
        "     shuffle = True\n",
        "     )\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F6_7Yz40AR5",
        "outputId": "1e2dfd8f-1132-4695-aa72-9a7c7db47125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 3, 224, 224])\n",
            "tensor(2.2318)\n",
            "tensor(-2.0357)\n"
          ]
        }
      ],
      "source": [
        "train_sample = iter(train_loader)\n",
        "data, label = train_sample.next()\n",
        "print(data.shape)\n",
        "print(data.max())\n",
        "print(data.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izK24-Mj68Fo",
        "outputId": "35d44395-ba0b-48ae-826e-a1fc9d285725"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.755007Z",
          "iopub.status.busy": "2020-12-02T18:34:14.753893Z",
          "iopub.status.idle": "2020-12-02T18:34:14.765112Z",
          "shell.execute_reply": "2020-12-02T18:34:14.764319Z"
        },
        "id": "cIKAyHd2IGQ7",
        "papermill": {
          "duration": 0.08523,
          "end_time": "2020-12-02T18:34:14.765245",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.680015",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"Available Vision Transformer Models: \")\n",
        "timm.list_models(\"vit*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.936128Z",
          "iopub.status.busy": "2020-12-02T18:34:14.924554Z",
          "iopub.status.idle": "2020-12-02T18:34:15.031764Z",
          "shell.execute_reply": "2020-12-02T18:34:15.030784Z"
        },
        "id": "Zx7qnjCwIGQ7",
        "papermill": {
          "duration": 0.197739,
          "end_time": "2020-12-02T18:34:15.031965",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.834226",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class ViTBase16(nn.Module):\n",
        "    def __init__(self, n_classes, pretrained=False):\n",
        "\n",
        "        super(ViTBase16, self).__init__()\n",
        "\n",
        "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
        "        if pretrained:\n",
        "            self.model.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "B53e5IZgY6RU"
      },
      "outputs": [],
      "source": [
        "model = ViTBase16(n_classes=4, pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "t-n8NI44vpcA"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMy-OEKUvvaU",
        "outputId": "6a05cc8d-456f-4d89-e668-f0debc5bc8d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djRJaLSVY9MU",
        "outputId": "5c25b296-ae56-480c-c1a7-dddfe7560f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
            "          Identity-2             [-1, 196, 768]               0\n",
            "        PatchEmbed-3             [-1, 196, 768]               0\n",
            "           Dropout-4             [-1, 197, 768]               0\n",
            "         LayerNorm-5             [-1, 197, 768]           1,536\n",
            "            Linear-6            [-1, 197, 2304]       1,771,776\n",
            "           Dropout-7         [-1, 12, 197, 197]               0\n",
            "            Linear-8             [-1, 197, 768]         590,592\n",
            "           Dropout-9             [-1, 197, 768]               0\n",
            "        Attention-10             [-1, 197, 768]               0\n",
            "         Identity-11             [-1, 197, 768]               0\n",
            "        LayerNorm-12             [-1, 197, 768]           1,536\n",
            "           Linear-13            [-1, 197, 3072]       2,362,368\n",
            "             GELU-14            [-1, 197, 3072]               0\n",
            "          Dropout-15            [-1, 197, 3072]               0\n",
            "           Linear-16             [-1, 197, 768]       2,360,064\n",
            "          Dropout-17             [-1, 197, 768]               0\n",
            "              Mlp-18             [-1, 197, 768]               0\n",
            "         Identity-19             [-1, 197, 768]               0\n",
            "            Block-20             [-1, 197, 768]               0\n",
            "        LayerNorm-21             [-1, 197, 768]           1,536\n",
            "           Linear-22            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-23         [-1, 12, 197, 197]               0\n",
            "           Linear-24             [-1, 197, 768]         590,592\n",
            "          Dropout-25             [-1, 197, 768]               0\n",
            "        Attention-26             [-1, 197, 768]               0\n",
            "         Identity-27             [-1, 197, 768]               0\n",
            "        LayerNorm-28             [-1, 197, 768]           1,536\n",
            "           Linear-29            [-1, 197, 3072]       2,362,368\n",
            "             GELU-30            [-1, 197, 3072]               0\n",
            "          Dropout-31            [-1, 197, 3072]               0\n",
            "           Linear-32             [-1, 197, 768]       2,360,064\n",
            "          Dropout-33             [-1, 197, 768]               0\n",
            "              Mlp-34             [-1, 197, 768]               0\n",
            "         Identity-35             [-1, 197, 768]               0\n",
            "            Block-36             [-1, 197, 768]               0\n",
            "        LayerNorm-37             [-1, 197, 768]           1,536\n",
            "           Linear-38            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-39         [-1, 12, 197, 197]               0\n",
            "           Linear-40             [-1, 197, 768]         590,592\n",
            "          Dropout-41             [-1, 197, 768]               0\n",
            "        Attention-42             [-1, 197, 768]               0\n",
            "         Identity-43             [-1, 197, 768]               0\n",
            "        LayerNorm-44             [-1, 197, 768]           1,536\n",
            "           Linear-45            [-1, 197, 3072]       2,362,368\n",
            "             GELU-46            [-1, 197, 3072]               0\n",
            "          Dropout-47            [-1, 197, 3072]               0\n",
            "           Linear-48             [-1, 197, 768]       2,360,064\n",
            "          Dropout-49             [-1, 197, 768]               0\n",
            "              Mlp-50             [-1, 197, 768]               0\n",
            "         Identity-51             [-1, 197, 768]               0\n",
            "            Block-52             [-1, 197, 768]               0\n",
            "        LayerNorm-53             [-1, 197, 768]           1,536\n",
            "           Linear-54            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-55         [-1, 12, 197, 197]               0\n",
            "           Linear-56             [-1, 197, 768]         590,592\n",
            "          Dropout-57             [-1, 197, 768]               0\n",
            "        Attention-58             [-1, 197, 768]               0\n",
            "         Identity-59             [-1, 197, 768]               0\n",
            "        LayerNorm-60             [-1, 197, 768]           1,536\n",
            "           Linear-61            [-1, 197, 3072]       2,362,368\n",
            "             GELU-62            [-1, 197, 3072]               0\n",
            "          Dropout-63            [-1, 197, 3072]               0\n",
            "           Linear-64             [-1, 197, 768]       2,360,064\n",
            "          Dropout-65             [-1, 197, 768]               0\n",
            "              Mlp-66             [-1, 197, 768]               0\n",
            "         Identity-67             [-1, 197, 768]               0\n",
            "            Block-68             [-1, 197, 768]               0\n",
            "        LayerNorm-69             [-1, 197, 768]           1,536\n",
            "           Linear-70            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-71         [-1, 12, 197, 197]               0\n",
            "           Linear-72             [-1, 197, 768]         590,592\n",
            "          Dropout-73             [-1, 197, 768]               0\n",
            "        Attention-74             [-1, 197, 768]               0\n",
            "         Identity-75             [-1, 197, 768]               0\n",
            "        LayerNorm-76             [-1, 197, 768]           1,536\n",
            "           Linear-77            [-1, 197, 3072]       2,362,368\n",
            "             GELU-78            [-1, 197, 3072]               0\n",
            "          Dropout-79            [-1, 197, 3072]               0\n",
            "           Linear-80             [-1, 197, 768]       2,360,064\n",
            "          Dropout-81             [-1, 197, 768]               0\n",
            "              Mlp-82             [-1, 197, 768]               0\n",
            "         Identity-83             [-1, 197, 768]               0\n",
            "            Block-84             [-1, 197, 768]               0\n",
            "        LayerNorm-85             [-1, 197, 768]           1,536\n",
            "           Linear-86            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-87         [-1, 12, 197, 197]               0\n",
            "           Linear-88             [-1, 197, 768]         590,592\n",
            "          Dropout-89             [-1, 197, 768]               0\n",
            "        Attention-90             [-1, 197, 768]               0\n",
            "         Identity-91             [-1, 197, 768]               0\n",
            "        LayerNorm-92             [-1, 197, 768]           1,536\n",
            "           Linear-93            [-1, 197, 3072]       2,362,368\n",
            "             GELU-94            [-1, 197, 3072]               0\n",
            "          Dropout-95            [-1, 197, 3072]               0\n",
            "           Linear-96             [-1, 197, 768]       2,360,064\n",
            "          Dropout-97             [-1, 197, 768]               0\n",
            "              Mlp-98             [-1, 197, 768]               0\n",
            "         Identity-99             [-1, 197, 768]               0\n",
            "           Block-100             [-1, 197, 768]               0\n",
            "       LayerNorm-101             [-1, 197, 768]           1,536\n",
            "          Linear-102            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-103         [-1, 12, 197, 197]               0\n",
            "          Linear-104             [-1, 197, 768]         590,592\n",
            "         Dropout-105             [-1, 197, 768]               0\n",
            "       Attention-106             [-1, 197, 768]               0\n",
            "        Identity-107             [-1, 197, 768]               0\n",
            "       LayerNorm-108             [-1, 197, 768]           1,536\n",
            "          Linear-109            [-1, 197, 3072]       2,362,368\n",
            "            GELU-110            [-1, 197, 3072]               0\n",
            "         Dropout-111            [-1, 197, 3072]               0\n",
            "          Linear-112             [-1, 197, 768]       2,360,064\n",
            "         Dropout-113             [-1, 197, 768]               0\n",
            "             Mlp-114             [-1, 197, 768]               0\n",
            "        Identity-115             [-1, 197, 768]               0\n",
            "           Block-116             [-1, 197, 768]               0\n",
            "       LayerNorm-117             [-1, 197, 768]           1,536\n",
            "          Linear-118            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-119         [-1, 12, 197, 197]               0\n",
            "          Linear-120             [-1, 197, 768]         590,592\n",
            "         Dropout-121             [-1, 197, 768]               0\n",
            "       Attention-122             [-1, 197, 768]               0\n",
            "        Identity-123             [-1, 197, 768]               0\n",
            "       LayerNorm-124             [-1, 197, 768]           1,536\n",
            "          Linear-125            [-1, 197, 3072]       2,362,368\n",
            "            GELU-126            [-1, 197, 3072]               0\n",
            "         Dropout-127            [-1, 197, 3072]               0\n",
            "          Linear-128             [-1, 197, 768]       2,360,064\n",
            "         Dropout-129             [-1, 197, 768]               0\n",
            "             Mlp-130             [-1, 197, 768]               0\n",
            "        Identity-131             [-1, 197, 768]               0\n",
            "           Block-132             [-1, 197, 768]               0\n",
            "       LayerNorm-133             [-1, 197, 768]           1,536\n",
            "          Linear-134            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-135         [-1, 12, 197, 197]               0\n",
            "          Linear-136             [-1, 197, 768]         590,592\n",
            "         Dropout-137             [-1, 197, 768]               0\n",
            "       Attention-138             [-1, 197, 768]               0\n",
            "        Identity-139             [-1, 197, 768]               0\n",
            "       LayerNorm-140             [-1, 197, 768]           1,536\n",
            "          Linear-141            [-1, 197, 3072]       2,362,368\n",
            "            GELU-142            [-1, 197, 3072]               0\n",
            "         Dropout-143            [-1, 197, 3072]               0\n",
            "          Linear-144             [-1, 197, 768]       2,360,064\n",
            "         Dropout-145             [-1, 197, 768]               0\n",
            "             Mlp-146             [-1, 197, 768]               0\n",
            "        Identity-147             [-1, 197, 768]               0\n",
            "           Block-148             [-1, 197, 768]               0\n",
            "       LayerNorm-149             [-1, 197, 768]           1,536\n",
            "          Linear-150            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-151         [-1, 12, 197, 197]               0\n",
            "          Linear-152             [-1, 197, 768]         590,592\n",
            "         Dropout-153             [-1, 197, 768]               0\n",
            "       Attention-154             [-1, 197, 768]               0\n",
            "        Identity-155             [-1, 197, 768]               0\n",
            "       LayerNorm-156             [-1, 197, 768]           1,536\n",
            "          Linear-157            [-1, 197, 3072]       2,362,368\n",
            "            GELU-158            [-1, 197, 3072]               0\n",
            "         Dropout-159            [-1, 197, 3072]               0\n",
            "          Linear-160             [-1, 197, 768]       2,360,064\n",
            "         Dropout-161             [-1, 197, 768]               0\n",
            "             Mlp-162             [-1, 197, 768]               0\n",
            "        Identity-163             [-1, 197, 768]               0\n",
            "           Block-164             [-1, 197, 768]               0\n",
            "       LayerNorm-165             [-1, 197, 768]           1,536\n",
            "          Linear-166            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-167         [-1, 12, 197, 197]               0\n",
            "          Linear-168             [-1, 197, 768]         590,592\n",
            "         Dropout-169             [-1, 197, 768]               0\n",
            "       Attention-170             [-1, 197, 768]               0\n",
            "        Identity-171             [-1, 197, 768]               0\n",
            "       LayerNorm-172             [-1, 197, 768]           1,536\n",
            "          Linear-173            [-1, 197, 3072]       2,362,368\n",
            "            GELU-174            [-1, 197, 3072]               0\n",
            "         Dropout-175            [-1, 197, 3072]               0\n",
            "          Linear-176             [-1, 197, 768]       2,360,064\n",
            "         Dropout-177             [-1, 197, 768]               0\n",
            "             Mlp-178             [-1, 197, 768]               0\n",
            "        Identity-179             [-1, 197, 768]               0\n",
            "           Block-180             [-1, 197, 768]               0\n",
            "       LayerNorm-181             [-1, 197, 768]           1,536\n",
            "          Linear-182            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-183         [-1, 12, 197, 197]               0\n",
            "          Linear-184             [-1, 197, 768]         590,592\n",
            "         Dropout-185             [-1, 197, 768]               0\n",
            "       Attention-186             [-1, 197, 768]               0\n",
            "        Identity-187             [-1, 197, 768]               0\n",
            "       LayerNorm-188             [-1, 197, 768]           1,536\n",
            "          Linear-189            [-1, 197, 3072]       2,362,368\n",
            "            GELU-190            [-1, 197, 3072]               0\n",
            "         Dropout-191            [-1, 197, 3072]               0\n",
            "          Linear-192             [-1, 197, 768]       2,360,064\n",
            "         Dropout-193             [-1, 197, 768]               0\n",
            "             Mlp-194             [-1, 197, 768]               0\n",
            "        Identity-195             [-1, 197, 768]               0\n",
            "           Block-196             [-1, 197, 768]               0\n",
            "       LayerNorm-197             [-1, 197, 768]           1,536\n",
            "        Identity-198                  [-1, 768]               0\n",
            "          Linear-199                    [-1, 4]           3,076\n",
            "VisionTransformer-200                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 85,649,668\n",
            "Trainable params: 85,649,668\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 408.54\n",
            "Params size (MB): 326.73\n",
            "Estimated Total Size (MB): 735.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "model = model.to(device)\n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NsM6Fmo7o9A",
        "outputId": "873cb8d8-db26-45f0-fe83-bdb4f2730998"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1194, -0.3900,  0.1505, -0.5583],\n",
              "        [-0.0322,  0.3261,  0.0498,  0.1794],\n",
              "        [ 0.1753, -0.3765, -0.2668, -0.5543],\n",
              "        [ 0.5268, -0.4686,  0.6782,  0.4360],\n",
              "        [ 0.2178, -0.6117,  0.1143, -0.5424],\n",
              "        [-0.1976, -0.3004,  0.1406,  0.2453],\n",
              "        [-0.2154, -0.3759, -0.0427,  0.3615],\n",
              "        [ 0.0050, -0.6890,  0.1830, -0.3861],\n",
              "        [-0.7695, -0.0184, -0.3533,  0.0697],\n",
              "        [-0.4051, -0.3870,  0.2043,  0.0884],\n",
              "        [-0.4978, -0.7828, -0.1486,  0.3260],\n",
              "        [ 0.5500, -0.1505,  0.2793, -0.3788],\n",
              "        [-0.0877, -0.6342, -0.2530, -0.1161],\n",
              "        [ 0.3461, -0.1894,  0.5625, -0.0810],\n",
              "        [ 0.0796, -0.0666, -0.7042, -0.3583],\n",
              "        [ 0.9054, -0.1226,  0.3087, -0.2903]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = model(data.to(device))\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8k2xJ4o7vIk",
        "outputId": "e8bf0892-b62b-4301-b595-a562b1ac4a7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okUsH7RR7xo-",
        "outputId": "69acab4a-56e5-4799-a2e0-6189734aa008"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([16, 4])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmumFzdXH8TA",
        "outputId": "01f87b48-42e1-4eff-8fc6-bffb4e0d44f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.2557, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "print(criterion(pred, label.to(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiPV66oAyZmK",
        "outputId": "66d5ecd2-f89e-4f80-dd4a-8380c5ed3db2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LfJx-1alr5YN"
      },
      "outputs": [],
      "source": [
        "# Checking the model performance with out any training, on training set, so that we can \n",
        "# Conclude Later during that the model is atleast converging later on\n",
        "baseline_train_loss = 0.0\n",
        "baseline_train_accuracy = 0.0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for data, target in train_loader:\n",
        "    data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "    \n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    \n",
        "    # Calculate Accuracy\n",
        "    accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "    \n",
        "    # update training loss and accuracy\n",
        "    baseline_train_loss += loss\n",
        "    baseline_train_accuracy += accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrzRZIrrt-DG",
        "outputId": "d425942b-487e-4b54-9234-9bfeae54aead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training batches = 564\n",
            "Baseline Training Data Loss = 1.3190544843673706\n",
            "Baseline Training Data Accuracy = 34.443702697753906 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Total training batches = {}\".format(len(train_loader)))\n",
        "print(\"Baseline Training Data Loss = {}\".format(baseline_train_loss/len(train_loader)))\n",
        "print(\"Baseline Training Data Accuracy = {} %\".format(100*baseline_train_accuracy/len(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vMtoA_s8wJ_l"
      },
      "outputs": [],
      "source": [
        "baseline_valid_loss = 0.0\n",
        "baseline_valid_accuracy = 0.0\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for data, target in valid_loader:\n",
        "    data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "    \n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    \n",
        "    # Calculate Accuracy\n",
        "    accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "    \n",
        "    # update training loss and accuracy\n",
        "    baseline_valid_loss += loss\n",
        "    baseline_valid_accuracy += accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhhOFjKxwguw",
        "outputId": "62c90100-328b-4828-e888-328d431d543e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training batches = 71\n",
            "Baseline Validation Data Loss = 1.3233730792999268\n",
            "Baseline Validation Data Accuracy = 36.35563278198242 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Total training batches = {}\".format(len(valid_loader)))\n",
        "print(\"Baseline Validation Data Loss = {}\".format(baseline_valid_loss/len(valid_loader)))\n",
        "print(\"Baseline Validation Data Accuracy = {} %\".format(100*baseline_valid_accuracy/len(valid_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTBe5ay5733J",
        "outputId": "8a79646b-8fcd-4247-a0f8-46cb5d7d2659"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF9wOml18Ew4",
        "outputId": "c57ed18d-0f0f-4046-ee23-a21cd639fdb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-2.1179, device='cuda:0')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrrOQmZ98Gm4",
        "outputId": "3ddc48e3-0b1e-4065-9c11-2f2a86915f74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.1975, device='cuda:0')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "6HOprS49NXUo"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9gd8V84NXOJ",
        "outputId": "ffceac69-08b5-47fe-8f62-a05485d5caec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
            "          Identity-2             [-1, 196, 768]               0\n",
            "        PatchEmbed-3             [-1, 196, 768]               0\n",
            "           Dropout-4             [-1, 197, 768]               0\n",
            "         LayerNorm-5             [-1, 197, 768]           1,536\n",
            "            Linear-6            [-1, 197, 2304]       1,771,776\n",
            "           Dropout-7         [-1, 12, 197, 197]               0\n",
            "            Linear-8             [-1, 197, 768]         590,592\n",
            "           Dropout-9             [-1, 197, 768]               0\n",
            "        Attention-10             [-1, 197, 768]               0\n",
            "         Identity-11             [-1, 197, 768]               0\n",
            "        LayerNorm-12             [-1, 197, 768]           1,536\n",
            "           Linear-13            [-1, 197, 3072]       2,362,368\n",
            "             GELU-14            [-1, 197, 3072]               0\n",
            "          Dropout-15            [-1, 197, 3072]               0\n",
            "           Linear-16             [-1, 197, 768]       2,360,064\n",
            "          Dropout-17             [-1, 197, 768]               0\n",
            "              Mlp-18             [-1, 197, 768]               0\n",
            "         Identity-19             [-1, 197, 768]               0\n",
            "            Block-20             [-1, 197, 768]               0\n",
            "        LayerNorm-21             [-1, 197, 768]           1,536\n",
            "           Linear-22            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-23         [-1, 12, 197, 197]               0\n",
            "           Linear-24             [-1, 197, 768]         590,592\n",
            "          Dropout-25             [-1, 197, 768]               0\n",
            "        Attention-26             [-1, 197, 768]               0\n",
            "         Identity-27             [-1, 197, 768]               0\n",
            "        LayerNorm-28             [-1, 197, 768]           1,536\n",
            "           Linear-29            [-1, 197, 3072]       2,362,368\n",
            "             GELU-30            [-1, 197, 3072]               0\n",
            "          Dropout-31            [-1, 197, 3072]               0\n",
            "           Linear-32             [-1, 197, 768]       2,360,064\n",
            "          Dropout-33             [-1, 197, 768]               0\n",
            "              Mlp-34             [-1, 197, 768]               0\n",
            "         Identity-35             [-1, 197, 768]               0\n",
            "            Block-36             [-1, 197, 768]               0\n",
            "        LayerNorm-37             [-1, 197, 768]           1,536\n",
            "           Linear-38            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-39         [-1, 12, 197, 197]               0\n",
            "           Linear-40             [-1, 197, 768]         590,592\n",
            "          Dropout-41             [-1, 197, 768]               0\n",
            "        Attention-42             [-1, 197, 768]               0\n",
            "         Identity-43             [-1, 197, 768]               0\n",
            "        LayerNorm-44             [-1, 197, 768]           1,536\n",
            "           Linear-45            [-1, 197, 3072]       2,362,368\n",
            "             GELU-46            [-1, 197, 3072]               0\n",
            "          Dropout-47            [-1, 197, 3072]               0\n",
            "           Linear-48             [-1, 197, 768]       2,360,064\n",
            "          Dropout-49             [-1, 197, 768]               0\n",
            "              Mlp-50             [-1, 197, 768]               0\n",
            "         Identity-51             [-1, 197, 768]               0\n",
            "            Block-52             [-1, 197, 768]               0\n",
            "        LayerNorm-53             [-1, 197, 768]           1,536\n",
            "           Linear-54            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-55         [-1, 12, 197, 197]               0\n",
            "           Linear-56             [-1, 197, 768]         590,592\n",
            "          Dropout-57             [-1, 197, 768]               0\n",
            "        Attention-58             [-1, 197, 768]               0\n",
            "         Identity-59             [-1, 197, 768]               0\n",
            "        LayerNorm-60             [-1, 197, 768]           1,536\n",
            "           Linear-61            [-1, 197, 3072]       2,362,368\n",
            "             GELU-62            [-1, 197, 3072]               0\n",
            "          Dropout-63            [-1, 197, 3072]               0\n",
            "           Linear-64             [-1, 197, 768]       2,360,064\n",
            "          Dropout-65             [-1, 197, 768]               0\n",
            "              Mlp-66             [-1, 197, 768]               0\n",
            "         Identity-67             [-1, 197, 768]               0\n",
            "            Block-68             [-1, 197, 768]               0\n",
            "        LayerNorm-69             [-1, 197, 768]           1,536\n",
            "           Linear-70            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-71         [-1, 12, 197, 197]               0\n",
            "           Linear-72             [-1, 197, 768]         590,592\n",
            "          Dropout-73             [-1, 197, 768]               0\n",
            "        Attention-74             [-1, 197, 768]               0\n",
            "         Identity-75             [-1, 197, 768]               0\n",
            "        LayerNorm-76             [-1, 197, 768]           1,536\n",
            "           Linear-77            [-1, 197, 3072]       2,362,368\n",
            "             GELU-78            [-1, 197, 3072]               0\n",
            "          Dropout-79            [-1, 197, 3072]               0\n",
            "           Linear-80             [-1, 197, 768]       2,360,064\n",
            "          Dropout-81             [-1, 197, 768]               0\n",
            "              Mlp-82             [-1, 197, 768]               0\n",
            "         Identity-83             [-1, 197, 768]               0\n",
            "            Block-84             [-1, 197, 768]               0\n",
            "        LayerNorm-85             [-1, 197, 768]           1,536\n",
            "           Linear-86            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-87         [-1, 12, 197, 197]               0\n",
            "           Linear-88             [-1, 197, 768]         590,592\n",
            "          Dropout-89             [-1, 197, 768]               0\n",
            "        Attention-90             [-1, 197, 768]               0\n",
            "         Identity-91             [-1, 197, 768]               0\n",
            "        LayerNorm-92             [-1, 197, 768]           1,536\n",
            "           Linear-93            [-1, 197, 3072]       2,362,368\n",
            "             GELU-94            [-1, 197, 3072]               0\n",
            "          Dropout-95            [-1, 197, 3072]               0\n",
            "           Linear-96             [-1, 197, 768]       2,360,064\n",
            "          Dropout-97             [-1, 197, 768]               0\n",
            "              Mlp-98             [-1, 197, 768]               0\n",
            "         Identity-99             [-1, 197, 768]               0\n",
            "           Block-100             [-1, 197, 768]               0\n",
            "       LayerNorm-101             [-1, 197, 768]           1,536\n",
            "          Linear-102            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-103         [-1, 12, 197, 197]               0\n",
            "          Linear-104             [-1, 197, 768]         590,592\n",
            "         Dropout-105             [-1, 197, 768]               0\n",
            "       Attention-106             [-1, 197, 768]               0\n",
            "        Identity-107             [-1, 197, 768]               0\n",
            "       LayerNorm-108             [-1, 197, 768]           1,536\n",
            "          Linear-109            [-1, 197, 3072]       2,362,368\n",
            "            GELU-110            [-1, 197, 3072]               0\n",
            "         Dropout-111            [-1, 197, 3072]               0\n",
            "          Linear-112             [-1, 197, 768]       2,360,064\n",
            "         Dropout-113             [-1, 197, 768]               0\n",
            "             Mlp-114             [-1, 197, 768]               0\n",
            "        Identity-115             [-1, 197, 768]               0\n",
            "           Block-116             [-1, 197, 768]               0\n",
            "       LayerNorm-117             [-1, 197, 768]           1,536\n",
            "          Linear-118            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-119         [-1, 12, 197, 197]               0\n",
            "          Linear-120             [-1, 197, 768]         590,592\n",
            "         Dropout-121             [-1, 197, 768]               0\n",
            "       Attention-122             [-1, 197, 768]               0\n",
            "        Identity-123             [-1, 197, 768]               0\n",
            "       LayerNorm-124             [-1, 197, 768]           1,536\n",
            "          Linear-125            [-1, 197, 3072]       2,362,368\n",
            "            GELU-126            [-1, 197, 3072]               0\n",
            "         Dropout-127            [-1, 197, 3072]               0\n",
            "          Linear-128             [-1, 197, 768]       2,360,064\n",
            "         Dropout-129             [-1, 197, 768]               0\n",
            "             Mlp-130             [-1, 197, 768]               0\n",
            "        Identity-131             [-1, 197, 768]               0\n",
            "           Block-132             [-1, 197, 768]               0\n",
            "       LayerNorm-133             [-1, 197, 768]           1,536\n",
            "          Linear-134            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-135         [-1, 12, 197, 197]               0\n",
            "          Linear-136             [-1, 197, 768]         590,592\n",
            "         Dropout-137             [-1, 197, 768]               0\n",
            "       Attention-138             [-1, 197, 768]               0\n",
            "        Identity-139             [-1, 197, 768]               0\n",
            "       LayerNorm-140             [-1, 197, 768]           1,536\n",
            "          Linear-141            [-1, 197, 3072]       2,362,368\n",
            "            GELU-142            [-1, 197, 3072]               0\n",
            "         Dropout-143            [-1, 197, 3072]               0\n",
            "          Linear-144             [-1, 197, 768]       2,360,064\n",
            "         Dropout-145             [-1, 197, 768]               0\n",
            "             Mlp-146             [-1, 197, 768]               0\n",
            "        Identity-147             [-1, 197, 768]               0\n",
            "           Block-148             [-1, 197, 768]               0\n",
            "       LayerNorm-149             [-1, 197, 768]           1,536\n",
            "          Linear-150            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-151         [-1, 12, 197, 197]               0\n",
            "          Linear-152             [-1, 197, 768]         590,592\n",
            "         Dropout-153             [-1, 197, 768]               0\n",
            "       Attention-154             [-1, 197, 768]               0\n",
            "        Identity-155             [-1, 197, 768]               0\n",
            "       LayerNorm-156             [-1, 197, 768]           1,536\n",
            "          Linear-157            [-1, 197, 3072]       2,362,368\n",
            "            GELU-158            [-1, 197, 3072]               0\n",
            "         Dropout-159            [-1, 197, 3072]               0\n",
            "          Linear-160             [-1, 197, 768]       2,360,064\n",
            "         Dropout-161             [-1, 197, 768]               0\n",
            "             Mlp-162             [-1, 197, 768]               0\n",
            "        Identity-163             [-1, 197, 768]               0\n",
            "           Block-164             [-1, 197, 768]               0\n",
            "       LayerNorm-165             [-1, 197, 768]           1,536\n",
            "          Linear-166            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-167         [-1, 12, 197, 197]               0\n",
            "          Linear-168             [-1, 197, 768]         590,592\n",
            "         Dropout-169             [-1, 197, 768]               0\n",
            "       Attention-170             [-1, 197, 768]               0\n",
            "        Identity-171             [-1, 197, 768]               0\n",
            "       LayerNorm-172             [-1, 197, 768]           1,536\n",
            "          Linear-173            [-1, 197, 3072]       2,362,368\n",
            "            GELU-174            [-1, 197, 3072]               0\n",
            "         Dropout-175            [-1, 197, 3072]               0\n",
            "          Linear-176             [-1, 197, 768]       2,360,064\n",
            "         Dropout-177             [-1, 197, 768]               0\n",
            "             Mlp-178             [-1, 197, 768]               0\n",
            "        Identity-179             [-1, 197, 768]               0\n",
            "           Block-180             [-1, 197, 768]               0\n",
            "       LayerNorm-181             [-1, 197, 768]           1,536\n",
            "          Linear-182            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-183         [-1, 12, 197, 197]               0\n",
            "          Linear-184             [-1, 197, 768]         590,592\n",
            "         Dropout-185             [-1, 197, 768]               0\n",
            "       Attention-186             [-1, 197, 768]               0\n",
            "        Identity-187             [-1, 197, 768]               0\n",
            "       LayerNorm-188             [-1, 197, 768]           1,536\n",
            "          Linear-189            [-1, 197, 3072]       2,362,368\n",
            "            GELU-190            [-1, 197, 3072]               0\n",
            "         Dropout-191            [-1, 197, 3072]               0\n",
            "          Linear-192             [-1, 197, 768]       2,360,064\n",
            "         Dropout-193             [-1, 197, 768]               0\n",
            "             Mlp-194             [-1, 197, 768]               0\n",
            "        Identity-195             [-1, 197, 768]               0\n",
            "           Block-196             [-1, 197, 768]               0\n",
            "       LayerNorm-197             [-1, 197, 768]           1,536\n",
            "        Identity-198                  [-1, 768]               0\n",
            "          Linear-199                    [-1, 4]           3,076\n",
            "VisionTransformer-200                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 85,649,668\n",
            "Trainable params: 0\n",
            "Non-trainable params: 85,649,668\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 408.54\n",
            "Params size (MB): 326.73\n",
            "Estimated Total Size (MB): 735.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nqwPoUgNXLO",
        "outputId": "a743332a-3620-4ee7-ea2e-d3b19bd9a5a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
            "          Identity-2             [-1, 196, 768]               0\n",
            "        PatchEmbed-3             [-1, 196, 768]               0\n",
            "           Dropout-4             [-1, 197, 768]               0\n",
            "         LayerNorm-5             [-1, 197, 768]           1,536\n",
            "            Linear-6            [-1, 197, 2304]       1,771,776\n",
            "           Dropout-7         [-1, 12, 197, 197]               0\n",
            "            Linear-8             [-1, 197, 768]         590,592\n",
            "           Dropout-9             [-1, 197, 768]               0\n",
            "        Attention-10             [-1, 197, 768]               0\n",
            "         Identity-11             [-1, 197, 768]               0\n",
            "        LayerNorm-12             [-1, 197, 768]           1,536\n",
            "           Linear-13            [-1, 197, 3072]       2,362,368\n",
            "             GELU-14            [-1, 197, 3072]               0\n",
            "          Dropout-15            [-1, 197, 3072]               0\n",
            "           Linear-16             [-1, 197, 768]       2,360,064\n",
            "          Dropout-17             [-1, 197, 768]               0\n",
            "              Mlp-18             [-1, 197, 768]               0\n",
            "         Identity-19             [-1, 197, 768]               0\n",
            "            Block-20             [-1, 197, 768]               0\n",
            "        LayerNorm-21             [-1, 197, 768]           1,536\n",
            "           Linear-22            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-23         [-1, 12, 197, 197]               0\n",
            "           Linear-24             [-1, 197, 768]         590,592\n",
            "          Dropout-25             [-1, 197, 768]               0\n",
            "        Attention-26             [-1, 197, 768]               0\n",
            "         Identity-27             [-1, 197, 768]               0\n",
            "        LayerNorm-28             [-1, 197, 768]           1,536\n",
            "           Linear-29            [-1, 197, 3072]       2,362,368\n",
            "             GELU-30            [-1, 197, 3072]               0\n",
            "          Dropout-31            [-1, 197, 3072]               0\n",
            "           Linear-32             [-1, 197, 768]       2,360,064\n",
            "          Dropout-33             [-1, 197, 768]               0\n",
            "              Mlp-34             [-1, 197, 768]               0\n",
            "         Identity-35             [-1, 197, 768]               0\n",
            "            Block-36             [-1, 197, 768]               0\n",
            "        LayerNorm-37             [-1, 197, 768]           1,536\n",
            "           Linear-38            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-39         [-1, 12, 197, 197]               0\n",
            "           Linear-40             [-1, 197, 768]         590,592\n",
            "          Dropout-41             [-1, 197, 768]               0\n",
            "        Attention-42             [-1, 197, 768]               0\n",
            "         Identity-43             [-1, 197, 768]               0\n",
            "        LayerNorm-44             [-1, 197, 768]           1,536\n",
            "           Linear-45            [-1, 197, 3072]       2,362,368\n",
            "             GELU-46            [-1, 197, 3072]               0\n",
            "          Dropout-47            [-1, 197, 3072]               0\n",
            "           Linear-48             [-1, 197, 768]       2,360,064\n",
            "          Dropout-49             [-1, 197, 768]               0\n",
            "              Mlp-50             [-1, 197, 768]               0\n",
            "         Identity-51             [-1, 197, 768]               0\n",
            "            Block-52             [-1, 197, 768]               0\n",
            "        LayerNorm-53             [-1, 197, 768]           1,536\n",
            "           Linear-54            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-55         [-1, 12, 197, 197]               0\n",
            "           Linear-56             [-1, 197, 768]         590,592\n",
            "          Dropout-57             [-1, 197, 768]               0\n",
            "        Attention-58             [-1, 197, 768]               0\n",
            "         Identity-59             [-1, 197, 768]               0\n",
            "        LayerNorm-60             [-1, 197, 768]           1,536\n",
            "           Linear-61            [-1, 197, 3072]       2,362,368\n",
            "             GELU-62            [-1, 197, 3072]               0\n",
            "          Dropout-63            [-1, 197, 3072]               0\n",
            "           Linear-64             [-1, 197, 768]       2,360,064\n",
            "          Dropout-65             [-1, 197, 768]               0\n",
            "              Mlp-66             [-1, 197, 768]               0\n",
            "         Identity-67             [-1, 197, 768]               0\n",
            "            Block-68             [-1, 197, 768]               0\n",
            "        LayerNorm-69             [-1, 197, 768]           1,536\n",
            "           Linear-70            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-71         [-1, 12, 197, 197]               0\n",
            "           Linear-72             [-1, 197, 768]         590,592\n",
            "          Dropout-73             [-1, 197, 768]               0\n",
            "        Attention-74             [-1, 197, 768]               0\n",
            "         Identity-75             [-1, 197, 768]               0\n",
            "        LayerNorm-76             [-1, 197, 768]           1,536\n",
            "           Linear-77            [-1, 197, 3072]       2,362,368\n",
            "             GELU-78            [-1, 197, 3072]               0\n",
            "          Dropout-79            [-1, 197, 3072]               0\n",
            "           Linear-80             [-1, 197, 768]       2,360,064\n",
            "          Dropout-81             [-1, 197, 768]               0\n",
            "              Mlp-82             [-1, 197, 768]               0\n",
            "         Identity-83             [-1, 197, 768]               0\n",
            "            Block-84             [-1, 197, 768]               0\n",
            "        LayerNorm-85             [-1, 197, 768]           1,536\n",
            "           Linear-86            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-87         [-1, 12, 197, 197]               0\n",
            "           Linear-88             [-1, 197, 768]         590,592\n",
            "          Dropout-89             [-1, 197, 768]               0\n",
            "        Attention-90             [-1, 197, 768]               0\n",
            "         Identity-91             [-1, 197, 768]               0\n",
            "        LayerNorm-92             [-1, 197, 768]           1,536\n",
            "           Linear-93            [-1, 197, 3072]       2,362,368\n",
            "             GELU-94            [-1, 197, 3072]               0\n",
            "          Dropout-95            [-1, 197, 3072]               0\n",
            "           Linear-96             [-1, 197, 768]       2,360,064\n",
            "          Dropout-97             [-1, 197, 768]               0\n",
            "              Mlp-98             [-1, 197, 768]               0\n",
            "         Identity-99             [-1, 197, 768]               0\n",
            "           Block-100             [-1, 197, 768]               0\n",
            "       LayerNorm-101             [-1, 197, 768]           1,536\n",
            "          Linear-102            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-103         [-1, 12, 197, 197]               0\n",
            "          Linear-104             [-1, 197, 768]         590,592\n",
            "         Dropout-105             [-1, 197, 768]               0\n",
            "       Attention-106             [-1, 197, 768]               0\n",
            "        Identity-107             [-1, 197, 768]               0\n",
            "       LayerNorm-108             [-1, 197, 768]           1,536\n",
            "          Linear-109            [-1, 197, 3072]       2,362,368\n",
            "            GELU-110            [-1, 197, 3072]               0\n",
            "         Dropout-111            [-1, 197, 3072]               0\n",
            "          Linear-112             [-1, 197, 768]       2,360,064\n",
            "         Dropout-113             [-1, 197, 768]               0\n",
            "             Mlp-114             [-1, 197, 768]               0\n",
            "        Identity-115             [-1, 197, 768]               0\n",
            "           Block-116             [-1, 197, 768]               0\n",
            "       LayerNorm-117             [-1, 197, 768]           1,536\n",
            "          Linear-118            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-119         [-1, 12, 197, 197]               0\n",
            "          Linear-120             [-1, 197, 768]         590,592\n",
            "         Dropout-121             [-1, 197, 768]               0\n",
            "       Attention-122             [-1, 197, 768]               0\n",
            "        Identity-123             [-1, 197, 768]               0\n",
            "       LayerNorm-124             [-1, 197, 768]           1,536\n",
            "          Linear-125            [-1, 197, 3072]       2,362,368\n",
            "            GELU-126            [-1, 197, 3072]               0\n",
            "         Dropout-127            [-1, 197, 3072]               0\n",
            "          Linear-128             [-1, 197, 768]       2,360,064\n",
            "         Dropout-129             [-1, 197, 768]               0\n",
            "             Mlp-130             [-1, 197, 768]               0\n",
            "        Identity-131             [-1, 197, 768]               0\n",
            "           Block-132             [-1, 197, 768]               0\n",
            "       LayerNorm-133             [-1, 197, 768]           1,536\n",
            "          Linear-134            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-135         [-1, 12, 197, 197]               0\n",
            "          Linear-136             [-1, 197, 768]         590,592\n",
            "         Dropout-137             [-1, 197, 768]               0\n",
            "       Attention-138             [-1, 197, 768]               0\n",
            "        Identity-139             [-1, 197, 768]               0\n",
            "       LayerNorm-140             [-1, 197, 768]           1,536\n",
            "          Linear-141            [-1, 197, 3072]       2,362,368\n",
            "            GELU-142            [-1, 197, 3072]               0\n",
            "         Dropout-143            [-1, 197, 3072]               0\n",
            "          Linear-144             [-1, 197, 768]       2,360,064\n",
            "         Dropout-145             [-1, 197, 768]               0\n",
            "             Mlp-146             [-1, 197, 768]               0\n",
            "        Identity-147             [-1, 197, 768]               0\n",
            "           Block-148             [-1, 197, 768]               0\n",
            "       LayerNorm-149             [-1, 197, 768]           1,536\n",
            "          Linear-150            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-151         [-1, 12, 197, 197]               0\n",
            "          Linear-152             [-1, 197, 768]         590,592\n",
            "         Dropout-153             [-1, 197, 768]               0\n",
            "       Attention-154             [-1, 197, 768]               0\n",
            "        Identity-155             [-1, 197, 768]               0\n",
            "       LayerNorm-156             [-1, 197, 768]           1,536\n",
            "          Linear-157            [-1, 197, 3072]       2,362,368\n",
            "            GELU-158            [-1, 197, 3072]               0\n",
            "         Dropout-159            [-1, 197, 3072]               0\n",
            "          Linear-160             [-1, 197, 768]       2,360,064\n",
            "         Dropout-161             [-1, 197, 768]               0\n",
            "             Mlp-162             [-1, 197, 768]               0\n",
            "        Identity-163             [-1, 197, 768]               0\n",
            "           Block-164             [-1, 197, 768]               0\n",
            "       LayerNorm-165             [-1, 197, 768]           1,536\n",
            "          Linear-166            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-167         [-1, 12, 197, 197]               0\n",
            "          Linear-168             [-1, 197, 768]         590,592\n",
            "         Dropout-169             [-1, 197, 768]               0\n",
            "       Attention-170             [-1, 197, 768]               0\n",
            "        Identity-171             [-1, 197, 768]               0\n",
            "       LayerNorm-172             [-1, 197, 768]           1,536\n",
            "          Linear-173            [-1, 197, 3072]       2,362,368\n",
            "            GELU-174            [-1, 197, 3072]               0\n",
            "         Dropout-175            [-1, 197, 3072]               0\n",
            "          Linear-176             [-1, 197, 768]       2,360,064\n",
            "         Dropout-177             [-1, 197, 768]               0\n",
            "             Mlp-178             [-1, 197, 768]               0\n",
            "        Identity-179             [-1, 197, 768]               0\n",
            "           Block-180             [-1, 197, 768]               0\n",
            "       LayerNorm-181             [-1, 197, 768]           1,536\n",
            "          Linear-182            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-183         [-1, 12, 197, 197]               0\n",
            "          Linear-184             [-1, 197, 768]         590,592\n",
            "         Dropout-185             [-1, 197, 768]               0\n",
            "       Attention-186             [-1, 197, 768]               0\n",
            "        Identity-187             [-1, 197, 768]               0\n",
            "       LayerNorm-188             [-1, 197, 768]           1,536\n",
            "          Linear-189            [-1, 197, 3072]       2,362,368\n",
            "            GELU-190            [-1, 197, 3072]               0\n",
            "         Dropout-191            [-1, 197, 3072]               0\n",
            "          Linear-192             [-1, 197, 768]       2,360,064\n",
            "         Dropout-193             [-1, 197, 768]               0\n",
            "             Mlp-194             [-1, 197, 768]               0\n",
            "        Identity-195             [-1, 197, 768]               0\n",
            "           Block-196             [-1, 197, 768]               0\n",
            "       LayerNorm-197             [-1, 197, 768]           1,536\n",
            "        Identity-198                  [-1, 768]               0\n",
            "          Linear-199                    [-1, 4]           3,076\n",
            "VisionTransformer-200                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 85,649,668\n",
            "Trainable params: 4,612\n",
            "Non-trainable params: 85,645,056\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 408.54\n",
            "Params size (MB): 326.73\n",
            "Estimated Total Size (MB): 735.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "counter = 1\n",
        "for param in model.parameters():\n",
        "  counter += 1\n",
        "  if counter >= 150:\n",
        "    param.requires_grad = True\n",
        "  \n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npsCB0GFaTAb",
        "outputId": "e9aeedf4-1110-4778-dfc8-8fa4854eb45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "######### Into Validation Step ########\n",
            "[1 300]  Valid loss : 0.4015531539916992 \t Valid Accuracy : 0.8802816867828369\n",
            "Epoch : 1 Train epoch loss : 0.48445749282836914 \t Train Accuracy : 0.8348625302314758\n",
            "######### Into Validation Step ########\n",
            "[2 300]  Valid loss : 0.3780776262283325 \t Valid Accuracy : 0.8794013857841492\n",
            "Epoch : 2 Train epoch loss : 0.37267687916755676 \t Train Accuracy : 0.8735371828079224\n",
            "######### Into Validation Step ########\n",
            "[3 300]  Valid loss : 0.3200705051422119 \t Valid Accuracy : 0.9014084339141846\n",
            "Epoch : 3 Train epoch loss : 0.346443772315979 \t Train Accuracy : 0.8827422857284546\n",
            "######### Into Validation Step ########\n",
            "[4 300]  Valid loss : 0.33819031715393066 \t Valid Accuracy : 0.9084506630897522\n",
            "Epoch : 4 Train epoch loss : 0.33684760332107544 \t Train Accuracy : 0.8916149139404297\n",
            "######### Into Validation Step ########\n",
            "[5 300]  Valid loss : 0.3155050575733185 \t Valid Accuracy : 0.9137323498725891\n",
            "Epoch : 5 Train epoch loss : 0.3460366129875183 \t Train Accuracy : 0.8817597031593323\n"
          ]
        }
      ],
      "source": [
        "LR = 0.001\n",
        "epochs = 5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "check_every = 300\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "train_loss_array = []\n",
        "train_acc_array = []\n",
        "val_loss_array = []\n",
        "val_acc_array = []\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0.0\n",
        "  epoch_accuracy = 0.0\n",
        "  i = 1\n",
        "  for data, target in train_loader:\n",
        "    model.train()\n",
        "    data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "    # update training loss and accuracy\n",
        "    epoch_loss += loss\n",
        "    epoch_accuracy += accuracy\n",
        "    optimizer.step()\n",
        "    i += 1\n",
        "    if i % check_every == 0:\n",
        "      \n",
        "      # keep track of validation loss\n",
        "      valid_loss = 0.0\n",
        "      valid_accuracy = 0.0\n",
        "      print(\"######### Into Validation Step ########\")\n",
        "      ######################\n",
        "      # validate the model #\n",
        "      ######################\n",
        "      with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data, target in valid_loader:\n",
        "          # move tensors to GPU if CUDA is available\n",
        "          data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model(data)\n",
        "          # calculate the batch loss\n",
        "          loss = criterion(output, target)\n",
        "          # Calculate Accuracy\n",
        "          accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "          # update average validation loss and accuracy\n",
        "          valid_loss += loss\n",
        "          valid_accuracy += accuracy\n",
        "        val_loss_array.append(valid_loss/len(valid_loader)) \n",
        "        val_acc_array.append(valid_accuracy/len(valid_loader))\n",
        "        print(\"[{} {}]  Valid loss : {} \\t Valid Accuracy : {}\".format(epoch+1, i, valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)))\n",
        "    model.train()\n",
        "  train_loss_array.append(epoch_loss/len(train_loader)) \n",
        "  train_acc_array.append(epoch_accuracy/len(train_loader))\n",
        "  print(\"Epoch : {} Train epoch loss : {} \\t Train Accuracy : {}\".format(epoch+1, epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucKw2FqxOzpN",
        "outputId": "5bd43411-c5b7-4736-c8d5-4b992396cbc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3368, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loss_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcU57BcvOepb",
        "outputId": "d6252ae1-f3f3-4b51-8a25-92cf0e2bade1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(0.4016, device='cuda:0'),\n",
              " tensor(0.3781, device='cuda:0'),\n",
              " tensor(0.3201, device='cuda:0'),\n",
              " tensor(0.3382, device='cuda:0'),\n",
              " tensor(0.3155, device='cuda:0')]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_loss_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyWoOcmgO66T",
        "outputId": "2ec39f93-1be8-432e-9e07-3f9088070aab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(0.8349, device='cuda:0'),\n",
              " tensor(0.8735, device='cuda:0'),\n",
              " tensor(0.8827, device='cuda:0'),\n",
              " tensor(0.8916, device='cuda:0'),\n",
              " tensor(0.8818, device='cuda:0')]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_acc_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfVOU6QKOoxm",
        "outputId": "b54efe02-3989-4c94-8660-b70f4f16c7ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(0.8803, device='cuda:0'),\n",
              " tensor(0.8794, device='cuda:0'),\n",
              " tensor(0.9014, device='cuda:0'),\n",
              " tensor(0.9085, device='cuda:0'),\n",
              " tensor(0.9137, device='cuda:0')]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_acc_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV9PZ4kSxTWT",
        "outputId": "0320c7e7-88a4-4c4c-e8c0-510728a03e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "######### Into Validation Step ########\n",
            "[1 300]  Valid loss : 0.31054699420928955 \t Valid Accuracy : 0.9075704216957092\n",
            "Epoch : 1 Train epoch loss : 0.328321635723114 \t Train Accuracy : 0.8920581340789795\n",
            "######### Into Validation Step ########\n",
            "[2 300]  Valid loss : 0.3262495994567871 \t Valid Accuracy : 0.9005281329154968\n",
            "Epoch : 2 Train epoch loss : 0.3239913284778595 \t Train Accuracy : 0.8949393630027771\n",
            "######### Into Validation Step ########\n",
            "[3 300]  Valid loss : 0.2974778711795807 \t Valid Accuracy : 0.9146126508712769\n",
            "Epoch : 3 Train epoch loss : 0.3316201865673065 \t Train Accuracy : 0.8886302709579468\n",
            "######### Into Validation Step ########\n",
            "[4 300]  Valid loss : 0.2933146357536316 \t Valid Accuracy : 0.9242957830429077\n",
            "Epoch : 4 Train epoch loss : 0.32698413729667664 \t Train Accuracy : 0.8932697772979736\n",
            "######### Into Validation Step ########\n",
            "[5 300]  Valid loss : 0.2878643870353699 \t Valid Accuracy : 0.92341548204422\n",
            "Epoch : 5 Train epoch loss : 0.31686773896217346 \t Train Accuracy : 0.8979166150093079\n"
          ]
        }
      ],
      "source": [
        "LR = 0.001\n",
        "epochs = 5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "check_every = 300\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "train_loss_array = []\n",
        "train_acc_array = []\n",
        "val_loss_array = []\n",
        "val_acc_array = []\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0.0\n",
        "  epoch_accuracy = 0.0\n",
        "  i = 1\n",
        "  for data, target in train_loader:\n",
        "    model.train()\n",
        "    data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "    # update training loss and accuracy\n",
        "    epoch_loss += loss\n",
        "    epoch_accuracy += accuracy\n",
        "    optimizer.step()\n",
        "    i += 1\n",
        "    if i % check_every == 0:\n",
        "      \n",
        "      # keep track of validation loss\n",
        "      valid_loss = 0.0\n",
        "      valid_accuracy = 0.0\n",
        "      print(\"######### Into Validation Step ########\")\n",
        "      ######################\n",
        "      # validate the model #\n",
        "      ######################\n",
        "      with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data, target in valid_loader:\n",
        "          # move tensors to GPU if CUDA is available\n",
        "          data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model(data)\n",
        "          # calculate the batch loss\n",
        "          loss = criterion(output, target)\n",
        "          # Calculate Accuracy\n",
        "          accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "          # update average validation loss and accuracy\n",
        "          valid_loss += loss\n",
        "          valid_accuracy += accuracy\n",
        "        val_loss_array.append(valid_loss/len(valid_loader)) \n",
        "        val_acc_array.append(valid_accuracy/len(valid_loader))\n",
        "        print(\"[{} {}]  Valid loss : {} \\t Valid Accuracy : {}\".format(epoch+1, i, valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)))\n",
        "    model.train()\n",
        "  train_loss_array.append(epoch_loss/len(train_loader)) \n",
        "  train_acc_array.append(epoch_accuracy/len(train_loader))\n",
        "  print(\"Epoch : {} Train epoch loss : {} \\t Train Accuracy : {}\".format(epoch+1, epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOX00intXny0"
      },
      "source": [
        "On 14th epoch got the best validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAfP404_WVx4"
      },
      "source": [
        "### Test Data evaulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "it2QzqcNO9cs"
      },
      "outputs": [],
      "source": [
        "test_dataset = PollenDataset(test_df, transforms=transforms_valid)\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76OKNBHHWUz6",
        "outputId": "dea0a4c8-24fd-437e-e297-02b92e596e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Testing Model on Test dataset ########\n",
            "[5 565]  Test loss : 0.3325207829475403 \t Test Accuracy : 0.8943662047386169\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0.0\n",
        "test_accuracy = 0.0\n",
        "print(\"######### Testing Model on Test dataset ########\")\n",
        "######################\n",
        "# Testing the model #\n",
        "######################\n",
        "# To generate confusion matrix, saving the prediction and corresponding labels in a list\n",
        "prediction = []\n",
        "ground_truth = []\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for data, target in test_loader:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # Calculate Accuracy\n",
        "    prediction.extend(output.argmax(dim=1))\n",
        "    ground_truth.extend(target)\n",
        "    accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "    # update average validation loss and accuracy\n",
        "    test_loss += loss\n",
        "    test_accuracy += accuracy\n",
        "  print(\"[{} {}]  Test loss : {} \\t Test Accuracy : {}\".format(epoch+1, i, test_loss / len(test_loader), test_accuracy / len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "hFXdMmwlYd5B"
      },
      "outputs": [],
      "source": [
        "prediction_array = [int(i.cpu().detach().numpy()) for i in prediction]\n",
        "ground_truth_array = [int(i.cpu().detach().numpy()) for i in ground_truth]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZMn-WJ2YpIk"
      },
      "outputs": [],
      "source": [
        "prediction_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyCR6-KoXcl5",
        "outputId": "bdf80dcd-69e3-4df0-eae8-8fbac2e358d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.55      0.70       157\n",
            "           1       0.78      0.74      0.76        77\n",
            "           2       0.90      0.98      0.94       822\n",
            "           3       0.82      0.89      0.85        72\n",
            "\n",
            "    accuracy                           0.89      1128\n",
            "   macro avg       0.87      0.79      0.81      1128\n",
            "weighted avg       0.90      0.89      0.89      1128\n",
            "\n",
            "[[ 86   4  64   3]\n",
            " [  1  57  14   5]\n",
            " [  3  11 802   6]\n",
            " [  0   1   7  64]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(ground_truth_array, prediction_array))\n",
        "print(confusion_matrix(ground_truth_array, prediction_array))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_S_E7tuYWaQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Vision-Transformer for Pollen Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 2169.65242,
      "end_time": "2020-12-02T19:08:16.137317",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-12-02T18:32:06.484897",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
