{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 2169.65242,
      "end_time": "2020-12-02T19:08:16.137317",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-12-02T18:32:06.484897",
      "version": "2.1.0"
    },
    "colab": {
      "name": "Vision-Transformer for Pollen Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTRsPlACdQ_1",
        "outputId": "232e104c-12f0-4b0d-b841-31334da3abad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2020-12-02T18:32:25.025299Z",
          "iopub.status.busy": "2020-12-02T18:32:25.024308Z",
          "iopub.status.idle": "2020-12-02T18:34:10.700354Z",
          "shell.execute_reply": "2020-12-02T18:34:10.699640Z"
        },
        "papermill": {
          "duration": 105.718607,
          "end_time": "2020-12-02T18:34:10.700500",
          "exception": false,
          "start_time": "2020-12-02T18:32:24.981893",
          "status": "completed"
        },
        "tags": [],
        "id": "vsaq89tjIGQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ce1761-d094-4ef7-e008-88b4af149ebf"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 376 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:10.826084Z",
          "iopub.status.busy": "2020-12-02T18:34:10.824931Z",
          "iopub.status.idle": "2020-12-02T18:34:13.015202Z",
          "shell.execute_reply": "2020-12-02T18:34:13.015867Z"
        },
        "papermill": {
          "duration": 2.258623,
          "end_time": "2020-12-02T18:34:13.016037",
          "exception": false,
          "start_time": "2020-12-02T18:34:10.757414",
          "status": "completed"
        },
        "tags": [],
        "id": "Y5fsmaS4IGQ4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import timm\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn import model_selection, metrics\n",
        "from shutil import copyfile"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.273861Z",
          "iopub.status.busy": "2020-12-02T18:34:13.273082Z",
          "iopub.status.idle": "2020-12-02T18:34:13.288963Z",
          "shell.execute_reply": "2020-12-02T18:34:13.288196Z"
        },
        "papermill": {
          "duration": 0.083797,
          "end_time": "2020-12-02T18:34:13.289095",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.205298",
          "status": "completed"
        },
        "tags": [],
        "id": "WTO_w_wEIGQ5"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproductibility of results\n",
        "    \n",
        "    Arguments:\n",
        "        seed {int} -- Number of the seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed_everything(1001)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9b06LUPdD7p",
        "outputId": "2a1fa3cc-0c40-419e-d932-6f8b5192e112"
      },
      "source": [
        "!ls \"gdrive/MyDrive/Machine Vision and Image Processing/Project/Dataset\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pollen_data.zip  test.zip  train.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57XALDSLdfIi"
      },
      "source": [
        "!unzip -q \"gdrive/MyDrive/Machine Vision and Image Processing/Project/Dataset/Pollen_data.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO_RjEdTd95Q"
      },
      "source": [
        "## Loading the prepared Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4CB2Gp2cPe5"
      },
      "source": [
        "# general global variables\n",
        "DATA_PATH = \"Pollen_data\"\n",
        "IMAGES_PATH = \"Pollen_data/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.557875Z",
          "iopub.status.busy": "2020-12-02T18:34:13.557096Z",
          "iopub.status.idle": "2020-12-02T18:34:13.603956Z",
          "shell.execute_reply": "2020-12-02T18:34:13.603128Z"
        },
        "papermill": {
          "duration": 0.114526,
          "end_time": "2020-12-02T18:34:13.604087",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.489561",
          "status": "completed"
        },
        "tags": [],
        "id": "KZ84J__pIGQ5"
      },
      "source": [
        "df = pd.read_csv(os.path.join(DATA_PATH, \"data.csv\"))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.744267Z",
          "iopub.status.busy": "2020-12-02T18:34:13.736833Z",
          "iopub.status.idle": "2020-12-02T18:34:13.752203Z",
          "shell.execute_reply": "2020-12-02T18:34:13.752809Z"
        },
        "papermill": {
          "duration": 0.087447,
          "end_time": "2020-12-02T18:34:13.752968",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.665521",
          "status": "completed"
        },
        "tags": [],
        "id": "DOvQ3r_KIGQ6"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:13.889294Z",
          "iopub.status.busy": "2020-12-02T18:34:13.888176Z",
          "iopub.status.idle": "2020-12-02T18:34:14.103989Z",
          "shell.execute_reply": "2020-12-02T18:34:14.103314Z"
        },
        "papermill": {
          "duration": 0.288382,
          "end_time": "2020-12-02T18:34:14.104118",
          "exception": false,
          "start_time": "2020-12-02T18:34:13.815736",
          "status": "completed"
        },
        "tags": [],
        "id": "-DUxwZqnIGQ6"
      },
      "source": [
        "df.label.value_counts().plot(kind=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IamQAhx8KBge"
      },
      "source": [
        "# Here for splitting the data into train, test and validation. We will using train_test_split from sklearn\n",
        "\n",
        "# First divide the data into train data (80%) and remaining data(20%)\n",
        "# Secodn divide the remaining data into validation (10%) and test data(10%)\n",
        "train_df, remaining_df = model_selection.train_test_split(df, test_size=0.2, random_state=42, stratify=df.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N_RAonhLBrr"
      },
      "source": [
        "# Training data distribution\n",
        "train_df.label.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Training data distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiQiOcbELnfu"
      },
      "source": [
        "train_df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.240631Z",
          "iopub.status.busy": "2020-12-02T18:34:14.239815Z",
          "iopub.status.idle": "2020-12-02T18:34:14.272019Z",
          "shell.execute_reply": "2020-12-02T18:34:14.271271Z"
        },
        "papermill": {
          "duration": 0.102979,
          "end_time": "2020-12-02T18:34:14.272159",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.169180",
          "status": "completed"
        },
        "tags": [],
        "id": "cQKqI5lxIGQ6"
      },
      "source": [
        "remaining_df.label.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Except training data distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfyP5ENmLNAK"
      },
      "source": [
        "valid_df, test_df = model_selection.train_test_split(remaining_df, test_size=0.5, random_state=42, stratify=remaining_df.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2d8YNZyL5QL"
      },
      "source": [
        "valid_df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez-Q5OmmLV3G"
      },
      "source": [
        "valid_df.label.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Validation data distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEcVADBXMCAi"
      },
      "source": [
        "!ls \"gdrive/MyDrive/Machine Vision and Image Processing/Project/pretrained_model\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u6VH4sqL9o4"
      },
      "source": [
        "# Getting the pretrained transformer model into the current running environment\n",
        "!unzip -q \"gdrive/MyDrive/Machine Vision and Image Processing/Project/pretrained_model/jx_vit_base_p16_224-80ecf9dd.pth.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP2_rWBnb_AJ"
      },
      "source": [
        "MODEL_PATH = (\"jx_vit_base_p16_224-80ecf9dd.pth\")\n",
        "\n",
        "\n",
        "# model specific global variables\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "LR = 2e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1GPamiMgrA"
      },
      "source": [
        "DATA_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmzFbWa9MsLN",
        "outputId": "d36ce0df-7ec2-4943-d9a4-589d43451b40"
      },
      "source": [
        "len(df.values)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11279"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.419320Z",
          "iopub.status.busy": "2020-12-02T18:34:14.418142Z",
          "iopub.status.idle": "2020-12-02T18:34:14.444009Z",
          "shell.execute_reply": "2020-12-02T18:34:14.443354Z"
        },
        "papermill": {
          "duration": 0.106308,
          "end_time": "2020-12-02T18:34:14.444148",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.337840",
          "status": "completed"
        },
        "tags": [],
        "id": "X10x9aa4IGQ6"
      },
      "source": [
        "class PollenDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Helper Class to create the pytorch dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, data_path=DATA_PATH, transforms=None):\n",
        "        super().__init__()\n",
        "        self.df_data = df.values\n",
        "        self.data_path = data_path\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = \"images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name, label = self.df_data[index]\n",
        "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, torch.from_numpy(np.asarray(label, dtype=np.int64))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1COqUfYDPxD_",
        "outputId": "bf008db3-a031-49f4-ba33-6f2c605545d7"
      },
      "source": [
        "# Calculating the mean and standard deviation of my training df\n",
        "# Then will use this information for normalization of the images in Compose\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class PollenDatasetDistributionCalculator(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Helper Class to create the pytorch dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, data_path=DATA_PATH, transforms=None):\n",
        "        super().__init__()\n",
        "        self.df_data = df.values\n",
        "        self.data_path = data_path\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = \"images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name, label = self.df_data[index]\n",
        "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return (torch.from_numpy(np.asarray(image, dtype=np.float32).transpose((2,0,1))), label)\n",
        "\n",
        "train_dataset = PollenDatasetDistributionCalculator(train_df)\n",
        "loader = DataLoader(train_dataset,\n",
        "                          batch_size=10,\n",
        "                          num_workers=1,\n",
        "                          shuffle=False)\n",
        "\n",
        "mean = 0.\n",
        "std = 0.\n",
        "nb_samples = 0.\n",
        "for data, label in loader:\n",
        "    batch_samples = data.size(0)\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    mean += data.mean(2).sum(0)\n",
        "    std += data.std(2).sum(0)\n",
        "    nb_samples += batch_samples\n",
        "\n",
        "mean /= nb_samples\n",
        "std /= nb_samples\n",
        "\n",
        "print(mean)\n",
        "print(std)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([161.8874, 134.1203,  92.8091])\n",
            "tensor([54.6586, 54.8434, 44.0893])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.590922Z",
          "iopub.status.busy": "2020-12-02T18:34:14.589829Z",
          "iopub.status.idle": "2020-12-02T18:34:14.612461Z",
          "shell.execute_reply": "2020-12-02T18:34:14.611720Z"
        },
        "papermill": {
          "duration": 0.101631,
          "end_time": "2020-12-02T18:34:14.612584",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.510953",
          "status": "completed"
        },
        "tags": [],
        "id": "vj0xgpWNIGQ7"
      },
      "source": [
        "# create image augmentations\n",
        "\n",
        "# The Normalization metrics given that all the pixels are not rescaled i.e. are from 0 to 255\n",
        "# The normalization\n",
        "\n",
        "transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transforms_valid = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.755007Z",
          "iopub.status.busy": "2020-12-02T18:34:14.753893Z",
          "iopub.status.idle": "2020-12-02T18:34:14.765112Z",
          "shell.execute_reply": "2020-12-02T18:34:14.764319Z"
        },
        "papermill": {
          "duration": 0.08523,
          "end_time": "2020-12-02T18:34:14.765245",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.680015",
          "status": "completed"
        },
        "tags": [],
        "id": "cIKAyHd2IGQ7"
      },
      "source": [
        "print(\"Available Vision Transformer Models: \")\n",
        "timm.list_models(\"vit*\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:14.936128Z",
          "iopub.status.busy": "2020-12-02T18:34:14.924554Z",
          "iopub.status.idle": "2020-12-02T18:34:15.031764Z",
          "shell.execute_reply": "2020-12-02T18:34:15.030784Z"
        },
        "papermill": {
          "duration": 0.197739,
          "end_time": "2020-12-02T18:34:15.031965",
          "exception": false,
          "start_time": "2020-12-02T18:34:14.834226",
          "status": "completed"
        },
        "tags": [],
        "id": "Zx7qnjCwIGQ7"
      },
      "source": [
        "class ViTBase16(nn.Module):\n",
        "    def __init__(self, n_classes, pretrained=False):\n",
        "\n",
        "        super(ViTBase16, self).__init__()\n",
        "\n",
        "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
        "        if pretrained:\n",
        "            self.model.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x    "
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B53e5IZgY6RU"
      },
      "source": [
        "model = ViTBase16(n_classes=4, pretrained=True)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djRJaLSVY9MU",
        "outputId": "6a04c889-8e93-42cc-db62-615be8b328bb"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
            "          Identity-2             [-1, 196, 768]               0\n",
            "        PatchEmbed-3             [-1, 196, 768]               0\n",
            "           Dropout-4             [-1, 197, 768]               0\n",
            "         LayerNorm-5             [-1, 197, 768]           1,536\n",
            "            Linear-6            [-1, 197, 2304]       1,771,776\n",
            "           Dropout-7         [-1, 12, 197, 197]               0\n",
            "            Linear-8             [-1, 197, 768]         590,592\n",
            "           Dropout-9             [-1, 197, 768]               0\n",
            "        Attention-10             [-1, 197, 768]               0\n",
            "         Identity-11             [-1, 197, 768]               0\n",
            "        LayerNorm-12             [-1, 197, 768]           1,536\n",
            "           Linear-13            [-1, 197, 3072]       2,362,368\n",
            "             GELU-14            [-1, 197, 3072]               0\n",
            "          Dropout-15            [-1, 197, 3072]               0\n",
            "           Linear-16             [-1, 197, 768]       2,360,064\n",
            "          Dropout-17             [-1, 197, 768]               0\n",
            "              Mlp-18             [-1, 197, 768]               0\n",
            "         Identity-19             [-1, 197, 768]               0\n",
            "            Block-20             [-1, 197, 768]               0\n",
            "        LayerNorm-21             [-1, 197, 768]           1,536\n",
            "           Linear-22            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-23         [-1, 12, 197, 197]               0\n",
            "           Linear-24             [-1, 197, 768]         590,592\n",
            "          Dropout-25             [-1, 197, 768]               0\n",
            "        Attention-26             [-1, 197, 768]               0\n",
            "         Identity-27             [-1, 197, 768]               0\n",
            "        LayerNorm-28             [-1, 197, 768]           1,536\n",
            "           Linear-29            [-1, 197, 3072]       2,362,368\n",
            "             GELU-30            [-1, 197, 3072]               0\n",
            "          Dropout-31            [-1, 197, 3072]               0\n",
            "           Linear-32             [-1, 197, 768]       2,360,064\n",
            "          Dropout-33             [-1, 197, 768]               0\n",
            "              Mlp-34             [-1, 197, 768]               0\n",
            "         Identity-35             [-1, 197, 768]               0\n",
            "            Block-36             [-1, 197, 768]               0\n",
            "        LayerNorm-37             [-1, 197, 768]           1,536\n",
            "           Linear-38            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-39         [-1, 12, 197, 197]               0\n",
            "           Linear-40             [-1, 197, 768]         590,592\n",
            "          Dropout-41             [-1, 197, 768]               0\n",
            "        Attention-42             [-1, 197, 768]               0\n",
            "         Identity-43             [-1, 197, 768]               0\n",
            "        LayerNorm-44             [-1, 197, 768]           1,536\n",
            "           Linear-45            [-1, 197, 3072]       2,362,368\n",
            "             GELU-46            [-1, 197, 3072]               0\n",
            "          Dropout-47            [-1, 197, 3072]               0\n",
            "           Linear-48             [-1, 197, 768]       2,360,064\n",
            "          Dropout-49             [-1, 197, 768]               0\n",
            "              Mlp-50             [-1, 197, 768]               0\n",
            "         Identity-51             [-1, 197, 768]               0\n",
            "            Block-52             [-1, 197, 768]               0\n",
            "        LayerNorm-53             [-1, 197, 768]           1,536\n",
            "           Linear-54            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-55         [-1, 12, 197, 197]               0\n",
            "           Linear-56             [-1, 197, 768]         590,592\n",
            "          Dropout-57             [-1, 197, 768]               0\n",
            "        Attention-58             [-1, 197, 768]               0\n",
            "         Identity-59             [-1, 197, 768]               0\n",
            "        LayerNorm-60             [-1, 197, 768]           1,536\n",
            "           Linear-61            [-1, 197, 3072]       2,362,368\n",
            "             GELU-62            [-1, 197, 3072]               0\n",
            "          Dropout-63            [-1, 197, 3072]               0\n",
            "           Linear-64             [-1, 197, 768]       2,360,064\n",
            "          Dropout-65             [-1, 197, 768]               0\n",
            "              Mlp-66             [-1, 197, 768]               0\n",
            "         Identity-67             [-1, 197, 768]               0\n",
            "            Block-68             [-1, 197, 768]               0\n",
            "        LayerNorm-69             [-1, 197, 768]           1,536\n",
            "           Linear-70            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-71         [-1, 12, 197, 197]               0\n",
            "           Linear-72             [-1, 197, 768]         590,592\n",
            "          Dropout-73             [-1, 197, 768]               0\n",
            "        Attention-74             [-1, 197, 768]               0\n",
            "         Identity-75             [-1, 197, 768]               0\n",
            "        LayerNorm-76             [-1, 197, 768]           1,536\n",
            "           Linear-77            [-1, 197, 3072]       2,362,368\n",
            "             GELU-78            [-1, 197, 3072]               0\n",
            "          Dropout-79            [-1, 197, 3072]               0\n",
            "           Linear-80             [-1, 197, 768]       2,360,064\n",
            "          Dropout-81             [-1, 197, 768]               0\n",
            "              Mlp-82             [-1, 197, 768]               0\n",
            "         Identity-83             [-1, 197, 768]               0\n",
            "            Block-84             [-1, 197, 768]               0\n",
            "        LayerNorm-85             [-1, 197, 768]           1,536\n",
            "           Linear-86            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-87         [-1, 12, 197, 197]               0\n",
            "           Linear-88             [-1, 197, 768]         590,592\n",
            "          Dropout-89             [-1, 197, 768]               0\n",
            "        Attention-90             [-1, 197, 768]               0\n",
            "         Identity-91             [-1, 197, 768]               0\n",
            "        LayerNorm-92             [-1, 197, 768]           1,536\n",
            "           Linear-93            [-1, 197, 3072]       2,362,368\n",
            "             GELU-94            [-1, 197, 3072]               0\n",
            "          Dropout-95            [-1, 197, 3072]               0\n",
            "           Linear-96             [-1, 197, 768]       2,360,064\n",
            "          Dropout-97             [-1, 197, 768]               0\n",
            "              Mlp-98             [-1, 197, 768]               0\n",
            "         Identity-99             [-1, 197, 768]               0\n",
            "           Block-100             [-1, 197, 768]               0\n",
            "       LayerNorm-101             [-1, 197, 768]           1,536\n",
            "          Linear-102            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-103         [-1, 12, 197, 197]               0\n",
            "          Linear-104             [-1, 197, 768]         590,592\n",
            "         Dropout-105             [-1, 197, 768]               0\n",
            "       Attention-106             [-1, 197, 768]               0\n",
            "        Identity-107             [-1, 197, 768]               0\n",
            "       LayerNorm-108             [-1, 197, 768]           1,536\n",
            "          Linear-109            [-1, 197, 3072]       2,362,368\n",
            "            GELU-110            [-1, 197, 3072]               0\n",
            "         Dropout-111            [-1, 197, 3072]               0\n",
            "          Linear-112             [-1, 197, 768]       2,360,064\n",
            "         Dropout-113             [-1, 197, 768]               0\n",
            "             Mlp-114             [-1, 197, 768]               0\n",
            "        Identity-115             [-1, 197, 768]               0\n",
            "           Block-116             [-1, 197, 768]               0\n",
            "       LayerNorm-117             [-1, 197, 768]           1,536\n",
            "          Linear-118            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-119         [-1, 12, 197, 197]               0\n",
            "          Linear-120             [-1, 197, 768]         590,592\n",
            "         Dropout-121             [-1, 197, 768]               0\n",
            "       Attention-122             [-1, 197, 768]               0\n",
            "        Identity-123             [-1, 197, 768]               0\n",
            "       LayerNorm-124             [-1, 197, 768]           1,536\n",
            "          Linear-125            [-1, 197, 3072]       2,362,368\n",
            "            GELU-126            [-1, 197, 3072]               0\n",
            "         Dropout-127            [-1, 197, 3072]               0\n",
            "          Linear-128             [-1, 197, 768]       2,360,064\n",
            "         Dropout-129             [-1, 197, 768]               0\n",
            "             Mlp-130             [-1, 197, 768]               0\n",
            "        Identity-131             [-1, 197, 768]               0\n",
            "           Block-132             [-1, 197, 768]               0\n",
            "       LayerNorm-133             [-1, 197, 768]           1,536\n",
            "          Linear-134            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-135         [-1, 12, 197, 197]               0\n",
            "          Linear-136             [-1, 197, 768]         590,592\n",
            "         Dropout-137             [-1, 197, 768]               0\n",
            "       Attention-138             [-1, 197, 768]               0\n",
            "        Identity-139             [-1, 197, 768]               0\n",
            "       LayerNorm-140             [-1, 197, 768]           1,536\n",
            "          Linear-141            [-1, 197, 3072]       2,362,368\n",
            "            GELU-142            [-1, 197, 3072]               0\n",
            "         Dropout-143            [-1, 197, 3072]               0\n",
            "          Linear-144             [-1, 197, 768]       2,360,064\n",
            "         Dropout-145             [-1, 197, 768]               0\n",
            "             Mlp-146             [-1, 197, 768]               0\n",
            "        Identity-147             [-1, 197, 768]               0\n",
            "           Block-148             [-1, 197, 768]               0\n",
            "       LayerNorm-149             [-1, 197, 768]           1,536\n",
            "          Linear-150            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-151         [-1, 12, 197, 197]               0\n",
            "          Linear-152             [-1, 197, 768]         590,592\n",
            "         Dropout-153             [-1, 197, 768]               0\n",
            "       Attention-154             [-1, 197, 768]               0\n",
            "        Identity-155             [-1, 197, 768]               0\n",
            "       LayerNorm-156             [-1, 197, 768]           1,536\n",
            "          Linear-157            [-1, 197, 3072]       2,362,368\n",
            "            GELU-158            [-1, 197, 3072]               0\n",
            "         Dropout-159            [-1, 197, 3072]               0\n",
            "          Linear-160             [-1, 197, 768]       2,360,064\n",
            "         Dropout-161             [-1, 197, 768]               0\n",
            "             Mlp-162             [-1, 197, 768]               0\n",
            "        Identity-163             [-1, 197, 768]               0\n",
            "           Block-164             [-1, 197, 768]               0\n",
            "       LayerNorm-165             [-1, 197, 768]           1,536\n",
            "          Linear-166            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-167         [-1, 12, 197, 197]               0\n",
            "          Linear-168             [-1, 197, 768]         590,592\n",
            "         Dropout-169             [-1, 197, 768]               0\n",
            "       Attention-170             [-1, 197, 768]               0\n",
            "        Identity-171             [-1, 197, 768]               0\n",
            "       LayerNorm-172             [-1, 197, 768]           1,536\n",
            "          Linear-173            [-1, 197, 3072]       2,362,368\n",
            "            GELU-174            [-1, 197, 3072]               0\n",
            "         Dropout-175            [-1, 197, 3072]               0\n",
            "          Linear-176             [-1, 197, 768]       2,360,064\n",
            "         Dropout-177             [-1, 197, 768]               0\n",
            "             Mlp-178             [-1, 197, 768]               0\n",
            "        Identity-179             [-1, 197, 768]               0\n",
            "           Block-180             [-1, 197, 768]               0\n",
            "       LayerNorm-181             [-1, 197, 768]           1,536\n",
            "          Linear-182            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-183         [-1, 12, 197, 197]               0\n",
            "          Linear-184             [-1, 197, 768]         590,592\n",
            "         Dropout-185             [-1, 197, 768]               0\n",
            "       Attention-186             [-1, 197, 768]               0\n",
            "        Identity-187             [-1, 197, 768]               0\n",
            "       LayerNorm-188             [-1, 197, 768]           1,536\n",
            "          Linear-189            [-1, 197, 3072]       2,362,368\n",
            "            GELU-190            [-1, 197, 3072]               0\n",
            "         Dropout-191            [-1, 197, 3072]               0\n",
            "          Linear-192             [-1, 197, 768]       2,360,064\n",
            "         Dropout-193             [-1, 197, 768]               0\n",
            "             Mlp-194             [-1, 197, 768]               0\n",
            "        Identity-195             [-1, 197, 768]               0\n",
            "           Block-196             [-1, 197, 768]               0\n",
            "       LayerNorm-197             [-1, 197, 768]           1,536\n",
            "        Identity-198                  [-1, 768]               0\n",
            "          Linear-199                    [-1, 4]           3,076\n",
            "VisionTransformer-200                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 85,649,668\n",
            "Trainable params: 85,649,668\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 408.54\n",
            "Params size (MB): 326.73\n",
            "Estimated Total Size (MB): 735.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTWDSGzXaYda"
      },
      "source": [
        "train_dataset = PollenDataset(train_df, transforms=transforms_train)\n",
        "valid_dataset = PollenDataset(valid_df, transforms=transforms_valid)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWHDtVGmhlM_"
      },
      "source": [
        "train_loader = DataLoader(\n",
        "     dataset=train_dataset,\n",
        "     batch_size=BATCH_SIZE,\n",
        "     shuffle = True\n",
        "     )\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        "    )"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npsCB0GFaTAb",
        "outputId": "c071866a-d3f3-4cf4-b458-088ac408b901"
      },
      "source": [
        "epochs = 1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "check_every = 100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "i = 1\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0.0\n",
        "  epoch_accuracy = 0.0\n",
        "  model.train()\n",
        "  for data, target in train_loader:\n",
        "    data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "    # update training loss and accuracy\n",
        "    epoch_loss += loss\n",
        "    epoch_accuracy += accuracy\n",
        "    \n",
        "    optimizer.step()\n",
        "    i += 1\n",
        "\n",
        "  print(\"Training epoch loss : {} \\t Training Accuracy : {}\".format(epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)))\n",
        "\n",
        "  if i % check_every == 0:\n",
        "      \n",
        "    # keep track of validation loss\n",
        "    valid_loss = 0.0\n",
        "    valid_accuracy = 0.0\n",
        "\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "      data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.int64)\n",
        "      with torch.no_grad():\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # Calculate Accuracy\n",
        "        accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "        # update average validation loss and accuracy\n",
        "        valid_loss += loss\n",
        "        valid_accuracy += accuracy\n",
        "\n",
        "    print(\"Validation loss : {} \\t Validation Accuracy : {}\".format(valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU36P-K4YpbM"
      },
      "source": [
        "def train_one_epoch(train_loader, criterion, optimizer, device):\n",
        "        # keep track of training loss\n",
        "        epoch_loss = 0.0\n",
        "        epoch_accuracy = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        self.model.train()\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device.type == \"cuda\":\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            elif device.type == \"xla\":\n",
        "                data = data.to(device, dtype=torch.float32)\n",
        "                target = target.to(device, dtype=torch.int64)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = self.forward(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # Calculate Accuracy\n",
        "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "            # update training loss and accuracy\n",
        "            epoch_loss += loss\n",
        "            epoch_accuracy += accuracy\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
        "\n",
        "    def validate_one_epoch(self, valid_loader, criterion, device):\n",
        "        # keep track of validation loss\n",
        "        valid_loss = 0.0\n",
        "        valid_accuracy = 0.0\n",
        "\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        self.model.eval()\n",
        "        for data, target in valid_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device.type == \"cuda\":\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            elif device.type == \"xla\":\n",
        "                data = data.to(device, dtype=torch.float32)\n",
        "                target = target.to(device, dtype=torch.int64)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                output = self.model(data)\n",
        "                # calculate the batch loss\n",
        "                loss = criterion(output, target)\n",
        "                # Calculate Accuracy\n",
        "                accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "                # update average validation loss and accuracy\n",
        "                valid_loss += loss\n",
        "                valid_accuracy += accuracy\n",
        "\n",
        "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:15.199425Z",
          "iopub.status.busy": "2020-12-02T18:34:15.198635Z",
          "iopub.status.idle": "2020-12-02T18:34:15.236790Z",
          "shell.execute_reply": "2020-12-02T18:34:15.236128Z"
        },
        "papermill": {
          "duration": 0.131593,
          "end_time": "2020-12-02T18:34:15.236935",
          "exception": false,
          "start_time": "2020-12-02T18:34:15.105342",
          "status": "completed"
        },
        "tags": [],
        "id": "R11-LRXsIGQ7",
        "outputId": "084436df-e63b-4a7c-88a8-640042e1b6fd"
      },
      "source": [
        "def fit_tpu(\n",
        "    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None):\n",
        "\n",
        "    valid_loss_min = np.Inf  # track change in validation loss\n",
        "\n",
        "    # keeping track of losses as it happen\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    train_accs = []\n",
        "    valid_accs = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        gc.collect()\n",
        "        # para_train_loader = pl.ParallelLoader(train_loader, [device])\n",
        "\n",
        "        # xm.master_print(f\"{'='*50}\")\n",
        "        # xm.master_print(f\"EPOCH {epoch} - TRAINING...\")\n",
        "        train_loss, train_acc = model.train_one_epoch(\n",
        "            para_train_loader.per_device_loader(device), criterion, optimizer, device\n",
        "        )\n",
        "        xm.master_print(\n",
        "            f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\n\"\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        gc.collect()\n",
        "\n",
        "        if valid_loader is not None:\n",
        "            gc.collect()\n",
        "            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n",
        "            xm.master_print(f\"EPOCH {epoch} - VALIDATING...\")\n",
        "            valid_loss, valid_acc = model.validate_one_epoch(\n",
        "                para_valid_loader.per_device_loader(device), criterion, device\n",
        "            )\n",
        "            xm.master_print(f\"\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\n\")\n",
        "            valid_losses.append(valid_loss)\n",
        "            valid_accs.append(valid_acc)\n",
        "            gc.collect()\n",
        "\n",
        "            # save model if validation loss has decreased\n",
        "            if valid_loss <= valid_loss_min and epoch != 1:\n",
        "                xm.master_print(\n",
        "                    \"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\".format(\n",
        "                        valid_loss_min, valid_loss\n",
        "                    )\n",
        "                )\n",
        "            #                 xm.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "    return {\n",
        "        \"train_loss\": train_losses,\n",
        "        \"valid_losses\": valid_losses,\n",
        "        \"train_acc\": train_accs,\n",
        "        \"valid_acc\": valid_accs,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 15;\n",
              "                var nbb_unformatted_code = \"def fit_tpu(\\n    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None\\n):\\n\\n    valid_loss_min = np.Inf  # track change in validation loss\\n\\n    # keeping track of losses as it happen\\n    train_losses = []\\n    valid_losses = []\\n    train_accs = []\\n    valid_accs = []\\n\\n    for epoch in range(1, epochs + 1):\\n        gc.collect()\\n        para_train_loader = pl.ParallelLoader(train_loader, [device])\\n\\n        xm.master_print(f\\\"{'='*50}\\\")\\n        xm.master_print(f\\\"EPOCH {epoch} - TRAINING...\\\")\\n        train_loss, train_acc = model.train_one_epoch(\\n            para_train_loader.per_device_loader(device), criterion, optimizer, device\\n        )\\n        xm.master_print(\\n            f\\\"\\\\n\\\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\\\n\\\"\\n        )\\n        train_losses.append(train_loss)\\n        train_accs.append(train_acc)\\n        gc.collect()\\n\\n        if valid_loader is not None:\\n            gc.collect()\\n            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\\n            xm.master_print(f\\\"EPOCH {epoch} - VALIDATING...\\\")\\n            valid_loss, valid_acc = model.validate_one_epoch(\\n                para_valid_loader.per_device_loader(device), criterion, device\\n            )\\n            xm.master_print(f\\\"\\\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\\\n\\\")\\n            valid_losses.append(valid_loss)\\n            valid_accs.append(valid_acc)\\n            gc.collect()\\n\\n            # save model if validation loss has decreased\\n            if valid_loss <= valid_loss_min and epoch != 1:\\n                xm.master_print(\\n                    \\\"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\\\".format(\\n                        valid_loss_min, valid_loss\\n                    )\\n                )\\n            #                 xm.save(model.state_dict(), 'best_model.pth')\\n\\n            valid_loss_min = valid_loss\\n\\n    return {\\n        \\\"train_loss\\\": train_losses,\\n        \\\"valid_losses\\\": valid_losses,\\n        \\\"train_acc\\\": train_accs,\\n        \\\"valid_acc\\\": valid_accs,\\n    }\";\n",
              "                var nbb_formatted_code = \"def fit_tpu(\\n    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None\\n):\\n\\n    valid_loss_min = np.Inf  # track change in validation loss\\n\\n    # keeping track of losses as it happen\\n    train_losses = []\\n    valid_losses = []\\n    train_accs = []\\n    valid_accs = []\\n\\n    for epoch in range(1, epochs + 1):\\n        gc.collect()\\n        para_train_loader = pl.ParallelLoader(train_loader, [device])\\n\\n        xm.master_print(f\\\"{'='*50}\\\")\\n        xm.master_print(f\\\"EPOCH {epoch} - TRAINING...\\\")\\n        train_loss, train_acc = model.train_one_epoch(\\n            para_train_loader.per_device_loader(device), criterion, optimizer, device\\n        )\\n        xm.master_print(\\n            f\\\"\\\\n\\\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\\\n\\\"\\n        )\\n        train_losses.append(train_loss)\\n        train_accs.append(train_acc)\\n        gc.collect()\\n\\n        if valid_loader is not None:\\n            gc.collect()\\n            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\\n            xm.master_print(f\\\"EPOCH {epoch} - VALIDATING...\\\")\\n            valid_loss, valid_acc = model.validate_one_epoch(\\n                para_valid_loader.per_device_loader(device), criterion, device\\n            )\\n            xm.master_print(f\\\"\\\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\\\n\\\")\\n            valid_losses.append(valid_loss)\\n            valid_accs.append(valid_acc)\\n            gc.collect()\\n\\n            # save model if validation loss has decreased\\n            if valid_loss <= valid_loss_min and epoch != 1:\\n                xm.master_print(\\n                    \\\"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\\\".format(\\n                        valid_loss_min, valid_loss\\n                    )\\n                )\\n            #                 xm.save(model.state_dict(), 'best_model.pth')\\n\\n            valid_loss_min = valid_loss\\n\\n    return {\\n        \\\"train_loss\\\": train_losses,\\n        \\\"valid_losses\\\": valid_losses,\\n        \\\"train_acc\\\": train_accs,\\n        \\\"valid_acc\\\": valid_accs,\\n    }\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:15.386773Z",
          "iopub.status.busy": "2020-12-02T18:34:15.385757Z",
          "iopub.status.idle": "2020-12-02T18:34:17.883884Z",
          "shell.execute_reply": "2020-12-02T18:34:17.882840Z"
        },
        "papermill": {
          "duration": 2.57545,
          "end_time": "2020-12-02T18:34:17.884083",
          "exception": false,
          "start_time": "2020-12-02T18:34:15.308633",
          "status": "completed"
        },
        "tags": [],
        "id": "eKAbFqvdIGQ7",
        "outputId": "bc1f7485-aa43-4134-f1ad-385a3a485fd8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 16;\n",
              "                var nbb_unformatted_code = \"model = ViTBase16(n_classes=5, pretrained=True)\";\n",
              "                var nbb_formatted_code = \"model = ViTBase16(n_classes=5, pretrained=True)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:18.110856Z",
          "iopub.status.busy": "2020-12-02T18:34:18.107691Z",
          "iopub.status.idle": "2020-12-02T18:34:18.154359Z",
          "shell.execute_reply": "2020-12-02T18:34:18.154988Z"
        },
        "papermill": {
          "duration": 0.156612,
          "end_time": "2020-12-02T18:34:18.155150",
          "exception": false,
          "start_time": "2020-12-02T18:34:17.998538",
          "status": "completed"
        },
        "tags": [],
        "id": "uKV4un2iIGQ8",
        "outputId": "693bcd2c-8683-41f3-99b1-5baed63d084e"
      },
      "source": [
        "def _run():\n",
        "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
        "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        valid_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=8,\n",
        "    )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        dataset=valid_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        sampler=valid_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=8,\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = xm.xla_device()\n",
        "    model.to(device)\n",
        "\n",
        "    lr = LR * xm.xrt_world_size()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    xm.master_print(f\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\")\n",
        "    start_time = datetime.now()\n",
        "    xm.master_print(f\"Start Time: {start_time}\")\n",
        "\n",
        "    logs = fit_tpu(\n",
        "        model=model,\n",
        "        epochs=N_EPOCHS,\n",
        "        device=device,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        train_loader=train_loader,\n",
        "        valid_loader=valid_loader,\n",
        "    )\n",
        "\n",
        "    xm.master_print(f\"Execution time: {datetime.now() - start_time}\")\n",
        "\n",
        "    xm.master_print(\"Saving Model\")\n",
        "    xm.save(\n",
        "        model.state_dict(), f'model_5e_{datetime.now().strftime(\"%Y%m%d-%H%M\")}.pth'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 17;\n",
              "                var nbb_unformatted_code = \"def _run():\\n    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\\n    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\\n\\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\\n        train_dataset,\\n        num_replicas=xm.xrt_world_size(),\\n        rank=xm.get_ordinal(),\\n        shuffle=True,\\n    )\\n\\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\\n        valid_dataset,\\n        num_replicas=xm.xrt_world_size(),\\n        rank=xm.get_ordinal(),\\n        shuffle=False,\\n    )\\n\\n    train_loader = torch.utils.data.DataLoader(\\n        dataset=train_dataset,\\n        batch_size=BATCH_SIZE,\\n        sampler=train_sampler,\\n        drop_last=True,\\n        num_workers=8,\\n    )\\n\\n    valid_loader = torch.utils.data.DataLoader(\\n        dataset=valid_dataset,\\n        batch_size=BATCH_SIZE,\\n        sampler=valid_sampler,\\n        drop_last=True,\\n        num_workers=8,\\n    )\\n\\n    criterion = nn.CrossEntropyLoss()\\n    #     device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n    device = xm.xla_device()\\n    model.to(device)\\n\\n    lr = LR * xm.xrt_world_size()\\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\\n\\n    xm.master_print(f\\\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\\\")\\n    start_time = datetime.now()\\n    xm.master_print(f\\\"Start Time: {start_time}\\\")\\n\\n    logs = fit_tpu(\\n        model=model,\\n        epochs=N_EPOCHS,\\n        device=device,\\n        criterion=criterion,\\n        optimizer=optimizer,\\n        train_loader=train_loader,\\n        valid_loader=valid_loader,\\n    )\\n\\n    xm.master_print(f\\\"Execution time: {datetime.now() - start_time}\\\")\\n\\n    xm.master_print(\\\"Saving Model\\\")\\n    xm.save(\\n        model.state_dict(), f'model_5e_{datetime.now().strftime(\\\"%Y%m%d-%H%M\\\")}.pth'\\n    )\";\n",
              "                var nbb_formatted_code = \"def _run():\\n    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\\n    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\\n\\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\\n        train_dataset,\\n        num_replicas=xm.xrt_world_size(),\\n        rank=xm.get_ordinal(),\\n        shuffle=True,\\n    )\\n\\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\\n        valid_dataset,\\n        num_replicas=xm.xrt_world_size(),\\n        rank=xm.get_ordinal(),\\n        shuffle=False,\\n    )\\n\\n    train_loader = torch.utils.data.DataLoader(\\n        dataset=train_dataset,\\n        batch_size=BATCH_SIZE,\\n        sampler=train_sampler,\\n        drop_last=True,\\n        num_workers=8,\\n    )\\n\\n    valid_loader = torch.utils.data.DataLoader(\\n        dataset=valid_dataset,\\n        batch_size=BATCH_SIZE,\\n        sampler=valid_sampler,\\n        drop_last=True,\\n        num_workers=8,\\n    )\\n\\n    criterion = nn.CrossEntropyLoss()\\n    #     device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n    device = xm.xla_device()\\n    model.to(device)\\n\\n    lr = LR * xm.xrt_world_size()\\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\\n\\n    xm.master_print(f\\\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\\\")\\n    start_time = datetime.now()\\n    xm.master_print(f\\\"Start Time: {start_time}\\\")\\n\\n    logs = fit_tpu(\\n        model=model,\\n        epochs=N_EPOCHS,\\n        device=device,\\n        criterion=criterion,\\n        optimizer=optimizer,\\n        train_loader=train_loader,\\n        valid_loader=valid_loader,\\n    )\\n\\n    xm.master_print(f\\\"Execution time: {datetime.now() - start_time}\\\")\\n\\n    xm.master_print(\\\"Saving Model\\\")\\n    xm.save(\\n        model.state_dict(), f'model_5e_{datetime.now().strftime(\\\"%Y%m%d-%H%M\\\")}.pth'\\n    )\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-02T18:34:18.313245Z",
          "iopub.status.busy": "2020-12-02T18:34:18.312128Z",
          "iopub.status.idle": "2020-12-02T19:08:15.586913Z",
          "shell.execute_reply": "2020-12-02T19:08:15.587804Z"
        },
        "papermill": {
          "duration": 2037.357951,
          "end_time": "2020-12-02T19:08:15.588226",
          "exception": false,
          "start_time": "2020-12-02T18:34:18.230275",
          "status": "completed"
        },
        "tags": [],
        "id": "_gXKRqNBIGQ8",
        "outputId": "49198ab3-1df9-4fb2-b2d9-6a309c55ee5b"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    a = _run()\n",
        "\n",
        "\n",
        "# _run()\n",
        "FLAGS = {}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method=\"fork\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INITIALIZING TRAINING ON 8 TPU CORES\n",
            "Start Time: 2020-12-02 18:34:26.339168\n",
            "==================================================\n",
            "EPOCH 1 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 1.609375\n",
            "\tBATCH 21/150 - LOSS: 0.7734375\n",
            "\tBATCH 41/150 - LOSS: 0.33984375\n",
            "\tBATCH 61/150 - LOSS: 0.333984375\n",
            "\tBATCH 81/150 - LOSS: 0.314453125\n",
            "\tBATCH 101/150 - LOSS: 0.765625\n",
            "\tBATCH 121/150 - LOSS: 0.439453125\n",
            "\tBATCH 141/150 - LOSS: 0.451171875\n",
            "\n",
            "\t[TRAIN] EPOCH 1 - LOSS: 0.59765625, ACCURACY: 0.83203125\n",
            "\n",
            "EPOCH 1 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.419921875, ACCURACY: 0.84375\n",
            "\n",
            "==================================================\n",
            "EPOCH 2 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.458984375\n",
            "\tBATCH 21/150 - LOSS: 0.2734375\n",
            "\tBATCH 41/150 - LOSS: 0.1396484375\n",
            "\tBATCH 61/150 - LOSS: 0.177734375\n",
            "\tBATCH 81/150 - LOSS: 0.14453125\n",
            "\tBATCH 101/150 - LOSS: 0.5703125\n",
            "\tBATCH 121/150 - LOSS: 0.32421875\n",
            "\tBATCH 141/150 - LOSS: 0.60546875\n",
            "\n",
            "\t[TRAIN] EPOCH 2 - LOSS: 0.41796875, ACCURACY: 0.9140625\n",
            "\n",
            "EPOCH 2 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.4140625, ACCURACY: 0.83984375\n",
            "\n",
            "Validation loss decreased (0.4199 --> 0.4141).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 3 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.20703125\n",
            "\tBATCH 21/150 - LOSS: 0.5625\n",
            "\tBATCH 41/150 - LOSS: 0.15625\n",
            "\tBATCH 61/150 - LOSS: 0.2373046875\n",
            "\tBATCH 81/150 - LOSS: 0.208984375\n",
            "\tBATCH 101/150 - LOSS: 0.435546875\n",
            "\tBATCH 121/150 - LOSS: 0.28515625\n",
            "\tBATCH 141/150 - LOSS: 0.337890625\n",
            "\n",
            "\t[TRAIN] EPOCH 3 - LOSS: 0.39453125, ACCURACY: 0.9140625\n",
            "\n",
            "EPOCH 3 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.404296875, ACCURACY: 0.83984375\n",
            "\n",
            "Validation loss decreased (0.4141 --> 0.4043).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 4 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.17578125\n",
            "\tBATCH 21/150 - LOSS: 0.15625\n",
            "\tBATCH 41/150 - LOSS: 0.154296875\n",
            "\tBATCH 61/150 - LOSS: 0.11865234375\n",
            "\tBATCH 81/150 - LOSS: 0.1298828125\n",
            "\tBATCH 101/150 - LOSS: 0.36328125\n",
            "\tBATCH 121/150 - LOSS: 0.208984375\n",
            "\tBATCH 141/150 - LOSS: 0.333984375\n",
            "\n",
            "\t[TRAIN] EPOCH 4 - LOSS: 0.369140625, ACCURACY: 0.921875\n",
            "\n",
            "EPOCH 4 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.3984375, ACCURACY: 0.859375\n",
            "\n",
            "Validation loss decreased (0.4043 --> 0.3984).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 5 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.5390625\n",
            "\tBATCH 21/150 - LOSS: 0.1865234375\n",
            "\tBATCH 41/150 - LOSS: 0.263671875\n",
            "\tBATCH 61/150 - LOSS: 0.1328125\n",
            "\tBATCH 81/150 - LOSS: 0.10498046875\n",
            "\tBATCH 101/150 - LOSS: 0.390625\n",
            "\tBATCH 121/150 - LOSS: 0.2890625\n",
            "\tBATCH 141/150 - LOSS: 0.318359375\n",
            "\n",
            "\t[TRAIN] EPOCH 5 - LOSS: 0.357421875, ACCURACY: 0.921875\n",
            "\n",
            "EPOCH 5 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.416015625, ACCURACY: 0.84375\n",
            "\n",
            "==================================================\n",
            "EPOCH 6 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.51953125\n",
            "\tBATCH 21/150 - LOSS: 0.27734375\n",
            "\tBATCH 41/150 - LOSS: 0.2138671875\n",
            "\tBATCH 61/150 - LOSS: 0.1630859375\n",
            "\tBATCH 81/150 - LOSS: 0.19140625\n",
            "\tBATCH 101/150 - LOSS: 0.60546875\n",
            "\tBATCH 121/150 - LOSS: 0.271484375\n",
            "\tBATCH 141/150 - LOSS: 0.1943359375\n",
            "\n",
            "\t[TRAIN] EPOCH 6 - LOSS: 0.34375, ACCURACY: 0.92578125\n",
            "\n",
            "EPOCH 6 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.41796875, ACCURACY: 0.8515625\n",
            "\n",
            "==================================================\n",
            "EPOCH 7 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.3125\n",
            "\tBATCH 21/150 - LOSS: 0.30078125\n",
            "\tBATCH 41/150 - LOSS: 0.2041015625\n",
            "\tBATCH 61/150 - LOSS: 0.3515625\n",
            "\tBATCH 81/150 - LOSS: 0.0849609375\n",
            "\tBATCH 101/150 - LOSS: 0.408203125\n",
            "\tBATCH 121/150 - LOSS: 0.146484375\n",
            "\tBATCH 141/150 - LOSS: 0.2001953125\n",
            "\n",
            "\t[TRAIN] EPOCH 7 - LOSS: 0.30078125, ACCURACY: 0.94140625\n",
            "\n",
            "EPOCH 7 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.40625, ACCURACY: 0.85546875\n",
            "\n",
            "Validation loss decreased (0.4180 --> 0.4062).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 8 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.16015625\n",
            "\tBATCH 21/150 - LOSS: 0.181640625\n",
            "\tBATCH 41/150 - LOSS: 0.083984375\n",
            "\tBATCH 61/150 - LOSS: 0.142578125\n",
            "\tBATCH 81/150 - LOSS: 0.11962890625\n",
            "\tBATCH 101/150 - LOSS: 0.2197265625\n",
            "\tBATCH 121/150 - LOSS: 0.1875\n",
            "\tBATCH 141/150 - LOSS: 0.33984375\n",
            "\n",
            "\t[TRAIN] EPOCH 8 - LOSS: 0.28515625, ACCURACY: 0.94140625\n",
            "\n",
            "EPOCH 8 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.40625, ACCURACY: 0.87109375\n",
            "\n",
            "Validation loss decreased (0.4062 --> 0.4062).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 9 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.435546875\n",
            "\tBATCH 21/150 - LOSS: 0.39453125\n",
            "\tBATCH 41/150 - LOSS: 0.212890625\n",
            "\tBATCH 61/150 - LOSS: 0.0830078125\n",
            "\tBATCH 81/150 - LOSS: 0.07958984375\n",
            "\tBATCH 101/150 - LOSS: 0.34765625\n",
            "\tBATCH 121/150 - LOSS: 0.279296875\n",
            "\tBATCH 141/150 - LOSS: 0.2470703125\n",
            "\n",
            "\t[TRAIN] EPOCH 9 - LOSS: 0.2890625, ACCURACY: 0.9453125\n",
            "\n",
            "EPOCH 9 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.41796875, ACCURACY: 0.87109375\n",
            "\n",
            "==================================================\n",
            "EPOCH 10 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.38671875\n",
            "\tBATCH 21/150 - LOSS: 0.2119140625\n",
            "\tBATCH 41/150 - LOSS: 0.06884765625\n",
            "\tBATCH 61/150 - LOSS: 0.1806640625\n",
            "\tBATCH 81/150 - LOSS: 0.0546875\n",
            "\tBATCH 101/150 - LOSS: 0.19140625\n",
            "\tBATCH 121/150 - LOSS: 0.197265625\n",
            "\tBATCH 141/150 - LOSS: 0.328125\n",
            "\n",
            "\t[TRAIN] EPOCH 10 - LOSS: 0.28125, ACCURACY: 0.9453125\n",
            "\n",
            "EPOCH 10 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.453125, ACCURACY: 0.83984375\n",
            "\n",
            "Execution time: 0:33:39.824880\n",
            "Saving Model\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 18;\n",
              "                var nbb_unformatted_code = \"# Start training processes\\ndef _mp_fn(rank, flags):\\n    torch.set_default_tensor_type(\\\"torch.FloatTensor\\\")\\n    a = _run()\\n\\n\\n# _run()\\nFLAGS = {}\\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method=\\\"fork\\\")\";\n",
              "                var nbb_formatted_code = \"# Start training processes\\ndef _mp_fn(rank, flags):\\n    torch.set_default_tensor_type(\\\"torch.FloatTensor\\\")\\n    a = _run()\\n\\n\\n# _run()\\nFLAGS = {}\\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method=\\\"fork\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.135774,
          "end_time": "2020-12-02T19:08:15.862334",
          "exception": false,
          "start_time": "2020-12-02T19:08:15.726560",
          "status": "completed"
        },
        "tags": [],
        "id": "o2odk_lTIGQ8"
      },
      "source": [
        "## Thanks a lot for reading all the way\n",
        "\n",
        "# <font size=4 color='blue'>If you find this notebook useful, leave an upvote, that motivates me to write more such notebooks.</font>"
      ]
    }
  ]
}